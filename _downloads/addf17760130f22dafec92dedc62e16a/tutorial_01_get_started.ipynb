{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Getting Started\n\n**Author**: Hongzheng Chen (hzchen@cs.cornell.edu)\n\nIn this tutorial, we demonstrate the basic usage of Allo.\n\n## Import Allo\nFirst we import the necessary packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import allo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algorithm Definition\nAllo leverages an algorithm-optimization decoupled paradigm, which means\nusers can first define the algorithm in a high-level language and then\noptimize the program with various hardware customization techniques (i.e.,\nschedule primitives). Here we show how to define a general matrix multiplication\n(GEMM) in the Allo DSL.\n\nWe first import the necessary data types from Allo. In this example, we\nuse ``int32`` as the data type for all the variables.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from allo.ir.types import int32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then define a function that takes two 32x32 matrices as inputs and\nreturns a 32x32 matrix as output. The variable declaration is defined\nas ``<name>: <type>[<shape>]``, and the function type is defined as\n``(<in_type0>, <in_type1>, ...) -> <out_type>``.\nWe require **strict type annotation** in Allo's kernels, which is different\nfrom directly programming in Python.\n\nInside the kernel, we provide a shorthand for the loop iterator. For example,\n``for i, j, k in allo.grid(32, 32, 32)`` is equivalent to the following\nnested for-loop:\n\n```python\nfor i in range(32):\n    for j in range(32):\n        for k in range(32):\n            # body\n```\nThe ``allo.grid`` API is used to define the iteration space of the loop.\nThe arguments denote the upper bounds of the loop iterators.\nNotice the above range-loop is also supported in the new Allo, so\nusers have more flexibility to define the loop structure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def gemm(A: int32[32, 32], B: int32[32, 32]) -> int32[32, 32]:\n    C: int32[32, 32] = 0\n    for i, j, k in allo.grid(32, 32, 32):\n        C[i, j] += A[i, k] * B[k, j]\n    return C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Schedule\nAfter defining the algorithm, we can start applying transformations to the\nkernel in order to achieve high performance. We call ``allo.customize`` to\ncreate a schedule for the kernel, where **schedule** denotes the set of\ntransformations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s = allo.customize(gemm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect the Intermediate Representation (IR)\nAllo leverage the [MLIR](https://mlir.llvm.org/) infrastructure to\nrepresent the program, and we can directly print out the IR by using\n``s.module``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(s.module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a close look at the generated IR. Basically an MLIR program is\na set of operations in different dialects, and the operations are referred\nto as **<dialect>.<ops>**. In this example, we can see that the generated IR\ncontains the following dialects:\n\n- ``func``: Used to define the function signature and the return of the function.\n- ``memref``: Used to define the shape and memory layout of the tensors.\n- ``affine``: Used to define the loop structure.\n- ``arith``: Used to conduct actual arithmetic operations.\n- ``linalg``: Currently only used to initialize the tensors.\n\nAnd the inner-most dot-product is explicitly represented by a sequence of load/store\noperations and some arithmetic operations.\nAllo also attaches some attributes to the operations, including the tensor\nnames, loop names, and operation names, which are further used for optimization.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply Transformations\nNext, we start transforming the program by using the schedule primitives.\nWe can refer to the loops by using the loop names. For example, to split\nthe outer-most loop into two, we can call the ``.split()`` primitive as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s.split(\"i\", factor=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can print out the IR again to see the effect of the transformation.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In the Allo DSL, all the transformations are applied **immediately**,\n  so users can directly see the changes after they apply the transformations.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(s.module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the outer-most loop is split into two loops, and the\noriginal loop is replaced by the two new loops. The new loops are named\nas ``i.outer`` and ``i.inner``.\n\nSimilarly, we can split the ``j`` loop:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s.split(\"j\", factor=8)\nprint(s.module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can further reorder the loops by using ``.reorder()``. For example, we\ncan move the splitted outer loops together, and move the splitted inner\nloops together.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s.reorder(\"i.outer\", \"j.outer\", \"i.inner\", \"j.inner\")\nprint(s.module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see the changes from the loop names in the generated IR.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Executable\nThe next step is to generate the executable from the schedule. We can\ndirectly call ``.build()`` function on the schedule and specify the target\nhardware as ``llvm``. By default, Allo will generate a LLVM program that\ncan be executed on the CPU. Otherwise, you can also specify the target as\n``vhls`` to generate a Vivado HLS program that can be synthesized to an FPGA\naccelerator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod = s.build(target=\"llvm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``s.build(target=\"llvm\")`` is equivalent to ``s.build()``.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the Inputs/Outputs for the Executable\nTo run the executable, we can generate random NumPy arrays as input data, and\ndirectly feed them into the executable. Allo will automatically handle the\ninput data and generate corresponding internal wrappers for LLVM to execute,\nbut we still need to make sure the data types are consistent. By default,\n``np.random.randint`` will generate ``np.int64`` data type, while we use ``int32``\nwhen defining our kernel function, so we need to explicitly cast the data type\nto ``np.int32``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nnp_A = np.random.randint(0, 100, (32, 32)).astype(np.int32)\nnp_B = np.random.randint(0, 100, (32, 32)).astype(np.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Executable\nWith the prepared inputs/outputs, we can feed them to our executable.\nNotice our module can return a new array as output, so we can directly\nassign the output to a new variable.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "allo_C = mod(np_A, np_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can do a sanity check to see if the results are correct.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "golden_C = np.matmul(np_A, np_B)\nnp.testing.assert_allclose(allo_C, golden_C, rtol=1e-5, atol=1e-5)\nprint(\"Results are correct!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}