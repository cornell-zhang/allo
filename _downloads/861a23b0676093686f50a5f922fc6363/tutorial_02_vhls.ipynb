{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Vivado HLS Backend\n\n**Author**: Hongzheng Chen (hzchen@cs.cornell.edu)\n\n\nIn this tutorial, we will demonstrate how to leverage the new Allo DSL frontend to generate\nVivado HLS code for FPGA.\n\n## Import Allo\nFirst, we import the necessary packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import allo\nfrom allo.ir.types import float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algorithm Definition\nWe again define a general matrix multiplication (GEMM) in this tutorial.\nHowever, we will make some changes to demonstrate more features of the DSL.\n\nWe can define the constants as follows, which denotes the matrix sizes:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "M, N, K = 1024, 1024, 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we define the main computation of the GEMM but use ``float32`` as the\ndata type. Notice that users can easily leverage the previously defined arguments\n(e.g., ``M``, ``N``, and ``K``) to construct the matrices, and Allo will\nautomatically captures the global variables.\n\nSince Allo has a strict type system, we need to be careful about the\ndata types of the variables. To initialize matrix ``C`` with all zeros, we\nneed to pass in a floating-point value ``0.0`` instead of an integer.\n\nWe also use the ``allo.reduction`` API to denote the reduction axis. The\nreduction axis is the loop iterator that is used to accumulate the result.\nIn this example, we use ``k`` as the reduction axis, which means the\ncomputation of ``C[i, j]`` will be accumulated along the ``k`` dimension.\nThis annotation is necessary for later optimizations, since Allo leverages\nthis information to generate correct intermediate buffers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def gemm(A: float32[M, K], B: float32[K, N]) -> float32[M, N]:\n    C: float32[M, N] = 0.0\n    for i, j in allo.grid(M, N):\n        for k in allo.reduction(K):\n            C[i, j] += A[i, k] * B[k, j]\n    return C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scalar-Vector Product for GEMM\n\nNext, we create a schedule for the GEMM and start to optimize the program.\nWe try to implement the **interleaving accumulation** technique presented in\n[this paper](https://arxiv.org/abs/1805.08288), which is also viewed as\nthe **scalar-vector product** since it changes the computation order of the\noriginal dot-product.\n\n<img src=\"file://../_static/scalar-vector-product.png\" width=\"600\">\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>To get more rational of this technique, please refer to the above mentioned\n   paper from Torsten Hoefler's group.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s = allo.customize(gemm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first reorder the inner reduction loop with the middle loop.\nThis is used to change the computation order of matrix multiplication.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s.reorder(\"k\", \"j\")\nprint(s.module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>This reordering seems to be easy, but it is impossible in the old Allo,\n   since the previous Allo directly generate reduction variables which make\n   the ``j`` loop becomes imperfect, while MLIR only supports reordering perfect\n   loops.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we create a new buffer for the output tensor ``C``.\nWe provide a ``.buffer_at()`` primitive for users to quickly create a new buffer\nalong a specific axis. Since Allo has attached all the tensors to the function,\nwe can directly use ``<func>.<tensor>`` to access a specific tensor in the schedule.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s.buffer_at(gemm.C, axis=\"i\")\nprint(s.module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above generated code, we can see that Allo automatically\ncreates an intermediate buffer ``%1`` for ``C`` and attach it inside the ``i`` loop.\nAlso two additional loop nested named ``j_init`` and ``j_back`` are created to\ninitialize and write the intermediate buffer back to output tensor.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, we pipeline the ``j`` loop in order to achieve the best performance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s.pipeline(\"j\")\nprint(s.module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Codegen for Vivado HLS\nSimilar to the CPU execution, we only need to change the target of the ``.build()`` function\nin order to target different backends. Here, we use ``vhls`` as the target to generate\nVivado HLS code, which will returns the generated code as a string.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "code = s.build(target=\"vhls\")\nprint(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the generated code preserves the same structure as the IR, and inserts\nnecessary headers and pragmas for Vivado HLS. The generated code can be directly passed\nto Vivado HLS to generate RTL designs.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We even provide an easy way to invoke Vivado HLS from Allo. Users can simply\ncreate a target platform, and configure the target with the ``vivado_hls`` compiler.\nThe ``project`` argument is used to specify the name of the Vivado HLS project folder.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# target = allo.Platform.xilinx_zc706\n# target.config(compiler=\"vivado_hls\", mode=\"debug\", project=\"gemm.prj\")\ntarget = \"vhls\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we call the ``.build()`` function with the specified ``target`` to generate\nthe Vivado HLS project.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod = s.build(target=target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You will see a ``gemm.prj`` folder is generated in the current directory:\n\n- ``host.cpp``: The host (CPU) code that invokes the generated accelerator.\n- ``kernel.cpp``: The generated accelerator code.\n- ``run.tcl``: The Vivado HLS script that can be used to generate the Vivado HLS project.\n- ``Makefile``: Defined some shorthands for compiling the project.\n\nTo run Vivado HLS, you can simply invoke the built module without passing any arguments into it.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>You need to configure the Vivado HLS environment before running the generated code.\n   We have the Vivado environment configured in the ``brg-zhang`` server, so you can directly\n   ``source /work/shared/common/allo/vitis_2019.2_opt.sh`` to set up the environment.</p></div>\n\n```python\nmod()\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After executing the above command, you will see the following output:\n\n```python\n+-------------------+-----------------------------------+\n| HLS Version       | Vivado HLS 2019.2.1               |\n| Product family    | zynq                              |\n| Target device     | xc7z020-clg484-1                  |\n| Top Model Name    | gemm                              |\n+-------------------+-----------------------------------+\n| Target CP         | 10.00 ns                          |\n| Estimated CP      | 8.052 ns                          |\n| Latency (cycles)  | Min 1077958658; Max 1077958658    |\n| Interval (cycles) | Min 1077958659; Max 1077958659    |\n| Resources         | Type        Used    Total    Util |\n|                   | --------  ------  -------  ------ |\n|                   | BRAM_18K       2      280      1% |\n|                   | DSP48E         5      220      2% |\n|                   | FF           862   106400      1% |\n|                   | LUT         1375    53200      3% |\n+-------------------+-----------------------------------+\n+---------------+--------------+------------+---------------------+---------------+------------------+\n|               |   Trip Count |    Latency |   Iteration Latency |   Pipeline II |   Pipeline Depth |\n|---------------+--------------+------------+---------------------+---------------+------------------|\n| Loop1         |         1024 |    2099200 |                2050 |           N/A |              N/A |\n| + Loop1.1     |         1024 |       2048 |                   2 |           N/A |              N/A |\n| l_S_i_j_i     |         1024 | 1075859456 |             1050644 |           N/A |              N/A |\n| + l_j_init    |         1024 |       1024 |                 N/A |             1 |                1 |\n| + l_S_k_k_l_j |      1048576 |    1048588 |                 N/A |             1 |               14 |\n| + l_j_back    |         1024 |       1025 |                 N/A |             1 |                3 |\n+---------------+--------------+------------+---------------------+---------------+------------------+\n* Units in clock cycles\n```\nFrom the above output, we can clearly see that all the loops inside the GEMM kernel are pipelined\nwith II=1.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}