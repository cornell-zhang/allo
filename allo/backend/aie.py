# Copyright Allo authors. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0
# mlir-aie commit: 8329b6
# pylint: disable=bad-builtin, no-name-in-module

import os
import subprocess
import re
import numpy as np
from .._mlir.ir import (
    RankedTensorType,
    MemRefType,
    FunctionType,
    TypeAttr,
    Location,
    InsertionPoint,
    FlatSymbolRefAttr,
    StringAttr,
    BlockArgument,
)
from .._mlir.dialects import (
    allo as allo_d,
    func as func_d,
)
from .._mlir.passmanager import PassManager as mlir_pass_manager

from .vitis import read_tensor_from_file
from ..utils import (
    get_dtype_and_shape_from_type,
    get_element_type_from_str,
)
from .utils import format_str, format_code
from .vitis import ctype_map
from ..passes import analyze_read_write_patterns


class DTensor:
    """
    A class to represent a distributed tensor.
    """

    def __init__(self, rank, comm_size, shape, dtype):
        self.rank = rank
        self.comm_size = comm_size
        # global shape
        self.shape = shape
        self.dtype = dtype
        # "S": Sharded
        # "R": Replicated
        self.placement = "R" * len(shape)
        self.offset = [0] * len(shape)
        self.local_shape = [s for s in shape]

    def set_placement(self, placement):
        """
        Set placement strategy for each dimension.

        Args:
            placement (str): String of 'S' and 'R' characters, one per dimension
        """
        if len(placement) != len(self.shape):
            raise ValueError(
                f"Placement length {len(placement)} doesn't match shape dimensions {len(self.shape)}"
            )
        self.placement = placement
        return self

    def set_subview(self, offset, local_shape):
        """
        Set the local subview parameters.

        Args:
            offset (list): Starting offsets for each dimension
            local_shape (list): Sizes for each dimension
        """
        if len(offset) != len(self.shape) or len(local_shape) != len(self.shape):
            raise ValueError(
                "Offset and local_shape must have same dimensions as shape"
            )
        self.offset = offset
        self.local_shape = local_shape
        return self

    def __str__(self):
        placement_desc = ", ".join(
            [
                f"{dim}: {'Sharded' if p == 'S' else 'Replicated'}"
                for dim, p in enumerate(self.placement)
            ]
        )
        return (
            f"DTensor(shape={self.shape}, dtype={self.dtype}, placement=[{placement_desc}], "
            f"offset={self.offset}, local_shape={self.local_shape})"
        )


class KernelFunction:
    """
    A class to represent a kernel function in the MLIR module.
    """

    def __init__(self, name, mapping, inputs, outputs):
        self.name = name
        self.mapping = mapping
        self.inputs = inputs  # List of tuples (dtype, shape)
        self.outputs = outputs  # List of tuples (dtype, shape)
        self.funcs = [None] * np.prod(
            mapping
        )  # List of MLIR functions for each mapping
        self.dtensors = [None] * np.prod(mapping)  # List of DTensors for each mapping

    def set_mlir_funcs(self, funcs):
        if len(funcs) != np.prod(self.mapping):
            raise ValueError("Number of MLIR functions must match the mapping size")
        self.funcs = funcs

    def set_dtensors(self, dtensors, idx):
        # Each function is associated with a list of dtensors
        if idx < 0 or idx >= np.prod(self.mapping):
            raise IndexError("Index out of range for the mapping size")
        self.dtensors[idx] = dtensors

    def __repr__(self):
        return f"KernelFunction(name={self.name}, mapping={self.mapping}, inputs={self.inputs}, outputs={self.outputs})"


host_header = """
//=============================================================================
// Auto generated by Allo
//=============================================================================

#include <boost/program_options.hpp>
#include <cstdint>
#include <fstream>
#include <iostream>
#include <sstream>
#include <string>
#include <vector>

#include "xrt/xrt_bo.h"
#include "xrt/xrt_device.h"
#include "xrt/xrt_kernel.h"

#include "test_utils.h"

namespace po = boost::program_options;

int main(int argc, const char *argv[]) {

  // ------------------------------------------------------
  // Parse program arguments
  // ------------------------------------------------------
  po::options_description desc("Allowed options");
  po::variables_map vm;
  test_utils::add_default_options(desc);

  test_utils::parse_options(argc, argv, desc, vm);
  int verbosity = vm["verbosity"].as<int>();
  int do_verify = vm["verify"].as<bool>();
  int n_iterations = vm["iters"].as<int>();
  int n_warmup_iterations = vm["warmup"].as<int>();
  int trace_size = vm["trace_sz"].as<int>();

  // Load instruction sequence
  std::vector<uint32_t> instr_v =
      test_utils::load_instr_sequence(vm["instr"].as<std::string>());
  if (verbosity >= 1)
    std::cout << "Sequence instr count: " << instr_v.size() << "\\n";

  // ------------------------------------------------------
  // Get device, load the xclbin & kernel and register them
  // ------------------------------------------------------
  // Get a device handle
  unsigned int device_index = 0;
  auto device = xrt::device(device_index);

  // Load the xclbin
  if (verbosity >= 1)
    std::cout << "Loading xclbin: " << vm["xclbin"].as<std::string>() << "\\n";
  auto xclbin = xrt::xclbin(vm["xclbin"].as<std::string>());

  // Load the kernel
  if (verbosity >= 1)
    std::cout << "Kernel opcode: " << vm["kernel"].as<std::string>() << "\\n";
  std::string Node = vm["kernel"].as<std::string>();

  // Get the kernel from the xclbin
  auto xkernels = xclbin.get_kernels();
  auto xkernel = *std::find_if(xkernels.begin(), xkernels.end(),
                               [Node, verbosity](xrt::xclbin::kernel &k) {
                                 auto name = k.get_name();
                                 if (verbosity >= 1) {
                                   std::cout << "Name: " << name << std::endl;
                                 }
                                 return name.rfind(Node, 0) == 0;
                               });
  auto kernelName = xkernel.get_name();

  // Register xclbin
  if (verbosity >= 1)
    std::cout << "Registering xclbin: " << vm["xclbin"].as<std::string>()
              << "\\n";
  device.register_xclbin(xclbin);

  // Get a hardware context
  if (verbosity >= 1)
    std::cout << "Getting hardware context.\\n";
  xrt::hw_context context(device, xclbin.get_uuid());

  // Get a kernel handle
  if (verbosity >= 1)
    std::cout << "Getting handle to kernel:" << kernelName << "\\n";
  auto kernel = xrt::kernel(context, kernelName);

  // ------------------------------------------------------
  // Initialize input/ output buffer sizes and sync them
  // ------------------------------------------------------
  auto bo_instr = xrt::bo(device, instr_v.size() * sizeof(int),
                          XCL_BO_FLAGS_CACHEABLE, kernel.group_id(1));
  void *bufInstr = bo_instr.map<void *>();
  memcpy(bufInstr, instr_v.data(), instr_v.size() * sizeof(int));

  std::ofstream ofile("output.data");
  if (!ofile.is_open()) {
      std::cerr << "Error: Could not open output file.\\n";
      return 1;
  }

"""

file_close_str = """  ofile.close();
  if (verbosity >= 1)
    std::cout << "Array has been written to output.data.\\n";
  return 0;
}
"""


def codegen_host(kernel_inputs, kernel_outputs):
    code = host_header
    inputs = [input for sublist in kernel_inputs.values() for input in sublist]
    outputs = [output for sublist in kernel_outputs.values() for output in sublist]
    with format_code(indent=2):
        # write input data
        for i, (dtype, shape) in enumerate(inputs):
            dtype = ctype_map[dtype]
            code += format_str(f'std::ifstream ifile{i}("input{i}.data");')
            code += format_str(f"if (!ifile{i}.is_open()) {{")
            code += format_str(
                '  std::cerr << "Error: Could not open input file.\\n";', strip=False
            )
            code += format_str("  return 1;", strip=False)
            code += format_str("}")
            size = np.prod(shape)
            code += format_str(
                f"auto bo_in{i} = xrt::bo(device, {size} * sizeof({dtype}),"
            )
            with format_code(indent=24):
                code += format_str(
                    f"XRT_BO_FLAGS_HOST_ONLY, kernel.group_id({i + 3}));"
                )
            code += format_str(f"{dtype} *bufIn{i} = bo_in{i}.map<{dtype} *>();")
            code += format_str(f"std::vector<{dtype}> srcVec{i};")
            code += format_str(f"for (int i = 0; i < {size}; i++) {{")
            with format_code(indent=4):
                code += format_str(f"{dtype} num;")
                code += format_str(f"ifile{i} >> num;")
                code += format_str(f"srcVec{i}.push_back(num);")
            code += format_str("}")
            code += format_str(
                f"memcpy(bufIn{i}, srcVec{i}.data(), (srcVec{i}.size() * sizeof({dtype})));"
            )
        for i, (dtype, shape) in enumerate(outputs):
            dtype = ctype_map[dtype]
            out_size = np.prod(shape)
            code += format_str(
                f"\nauto bo_out{i} = xrt::bo(device, {out_size} * sizeof({dtype}),",
                strip=False,
            )
            with format_code(indent=24):
                code += format_str(
                    f"XRT_BO_FLAGS_HOST_ONLY, kernel.group_id({len(inputs) + 2 + i}));"
                )
        code += format_str("if (verbosity >= 1)")
        code += format_str(
            '  std::cout << "Writing data into buffer objects.\\n";', strip=False
        )
        code += format_str("\nbo_instr.sync(XCL_BO_SYNC_BO_TO_DEVICE);", strip=False)
        for i in range(len(inputs)):
            code += format_str(f"bo_in{i}.sync(XCL_BO_SYNC_BO_TO_DEVICE);")
        # run kernels
        code += format_str("if (verbosity >= 1)")
        code += format_str('  std::cout << "Running Kernel.\\n";', strip=False)
        code += format_str(
            "\nauto start = std::chrono::high_resolution_clock::now();", strip=False
        )
        code += format_str("unsigned int opcode = 3;", strip=False)
        inbufs = ", ".join([f"bo_in{i}" for i in range(len(inputs))])
        outbufs = ", ".join([f"bo_out{i}" for i in range(len(outputs))])
        code += format_str("// gid: (opcode, instr, instr_size, ...)")
        code += format_str(
            f"auto run = kernel(opcode, bo_instr, instr_v.size(), {inbufs}, {outbufs});"
        )
        code += format_str("run.wait();")
        code += format_str(
            "\nauto end = std::chrono::high_resolution_clock::now();", strip=False
        )
        code += format_str(
            "float npu_time = std::chrono::duration_cast<std::chrono::microseconds>(end - start).count();"
        )
        code += format_str(
            'std::cout << "NPU execution time: " << npu_time << "us\\n";'
        )
        # get results
        for i, (dtype, shape) in enumerate(outputs):
            dtype = ctype_map[dtype]
            out_size = np.prod(shape)
            code += format_str(
                f"\nbo_out{i}.sync(XCL_BO_SYNC_BO_FROM_DEVICE);", strip=False
            )
            code += format_str(f"{dtype} *bufOut{i} = bo_out{i}.map<{dtype} *>();")
            code += format_str(f"for (uint32_t i = 0; i < {out_size}; i++) {{")
            code += format_str(f'  ofile << *(bufOut{i} + i) << "\\n";', strip=False)
            code += format_str("}")
        code += format_str("\n// Close files", strip=False)
        for i in range(len(inputs)):
            code += format_str(f"ifile{i}.close();")
        code += file_close_str
    return code


def get_stream_in_out(stream_info):
    """
    Computes the mapping of FIFO names to their producer (output) and consumer (input) cores.

    Parameters
    ----------
    stream_info (Dict[int, List[Tuple[str, str]]]):
        A dictionary where the key is a core ID (int), and the value is a list of tuples.
        Each tuple contains:
        - fifo_name (str): The name of the FIFO.
        - direction (str): The direction of data flow, either "in" (consumer) or "out" (producer).

    Returns
    -------
    Dict[str, Tuple[Optional[int], Optional[int]]]]:
        A dictionary where the key is a FIFO name, and the value is a tuple:
        - The first element is the producer function and the second element is the consumer function.
    """
    stream_in_out = {}
    for core, fifos in stream_info.items():
        for fifo_name, direction in fifos:
            if fifo_name not in stream_in_out:
                stream_in_out[fifo_name] = (None, None)
            if direction == "in":
                stream_in_out[fifo_name] = (stream_in_out[fifo_name][0], core)
            elif direction == "out":
                stream_in_out[fifo_name] = (core, stream_in_out[fifo_name][1])
    return stream_in_out


def get_public_funcs(mod):
    funcs = []
    top_func = None
    for func in mod.body.operations:
        if isinstance(func, func_d.FuncOp) and (
            "sym_visibility" not in func.attributes
            or func.attributes["sym_visibility"].value != "private"
        ):
            if func.attributes["sym_name"].value == "top":
                top_func = func
            else:
                funcs.append(func)
    return top_func, funcs


def inject_aie_kernels(mod):
    external_kernels = {}
    injected_kernels = set()
    with mod.context, Location.unknown():
        for func in mod.body.operations:
            external_kernels[func.attributes["sym_name"].value] = []
            for block in func.regions[0].blocks:
                for op in block.operations:
                    continue
                    if (
                        op.operation.name in {"linalg.add", "linalg.mul"}
                        and len(MemRefType(op.inputs[0].type).shape) == 1
                    ) or op.operation.name == "linalg.matmul":
                        op_name = op.operation.name.split(".")[1]
                        # Inject AIE kernel
                        func_type = func_d.FunctionType.get(
                            [op.inputs[0].type, op.inputs[1].type, op.outputs[0].type],
                            [],
                        )
                        dtype = str(op.inputs[0].type.element_type)
                        shape = MemRefType(op.inputs[0].type).shape
                        if op.operation.name in {"linalg.add", "linalg.mul"}:
                            kernel_name = f"{op_name}_{dtype}_vector"
                        else:  # linalg.matmul
                            kernel_name = f"matmul_{dtype}_i32"
                        func_d.CallOp(
                            [],
                            FlatSymbolRefAttr.get(kernel_name),
                            [op.inputs[0], op.inputs[1], op.outputs[0]],
                            ip=InsertionPoint(op),
                        )
                        op.erase()
                        external_kernels[func.attributes["sym_name"].value].append(
                            (op_name, dtype, shape)
                        )
                        if kernel_name in injected_kernels:
                            continue
                        injected_kernels.add(kernel_name)
                        kernel = func_d.FuncOp(
                            kernel_name,
                            func_type,
                            ip=InsertionPoint(func),
                        )
                        kernel.attributes["sym_visibility"] = StringAttr.get("private")
    return external_kernels


def codegen_external_kernels(external_kernels):
    code = ""
    code += "// External kernels generated by Allo\n\n"
    code += "#include <stdint.h>\n"
    code += "#include <stdio.h>\n"
    code += "#include <stdlib.h>\n"
    code += "#include <type_traits>\n"
    code += "#include <aie_api/aie.hpp>\n\n"
    generated_kernels = set()
    kernel_code = ""
    for _, kernel_lst in external_kernels.items():
        for kernel, dtype, shape in kernel_lst:
            if kernel in generated_kernels:
                continue
            ctype = ctype_map[dtype]
            if "bfloat" in ctype:
                ctype = "bfloat16"
            kernel_code += f"void {kernel}_{dtype}_vector"
            kernel_code += f"({ctype} *A_in, {ctype} *B_in, {ctype} *C_out)"
            kernel_code += " {\n"
            kernel_code += f"  eltwise_v{kernel}<{ctype}, {ctype}, {np.prod(shape)}>(A_in, B_in, C_out);\n"
            kernel_code += "}\n\n"
            generated_kernels.add(kernel)
    for kernel in generated_kernels:
        match kernel:
            case "add":
                code += '#include "add.cc"\n'
            case "mul":
                code += '#include "mul.cc"\n'
            case "matmul":
                code += '#include "mm.cc"\n'
    code += '\nextern "C" {\n\n'
    code += kernel_code
    code += '} // extern "C"\n'
    return code, generated_kernels


def process_stream_operations(func_str, streams, inputs, outputs, stream_ele_types):
    """
    Process a function string by replacing stream_get and stream_put calls with
    corresponding formatted FIFO code.

    Parameters
    ----------
        func_str (str): The input function string to be processed.
        streams (list): List of streams (each stream is a tuple/list where the first element is the stream name).
        inputs (list): List of input identifiers.
        outputs (list): List of output identifiers.
        stream_ele_types (dict): Dictionary mapping stream names to their element types.

    Returns
    -------
        str: The resulting formatted code.
    """
    code = ""
    with format_code(indent=6):
        lines = func_str.splitlines()
        for i in range(1, len(lines) - 2):
            line = lines[i]
            # Process stream_get
            if "stream_get" in line:
                # extract the argument id from the pattern "stream_get(%arg<digits>"
                m_get = re.search(r"stream_get\(%arg(\d+)", line)
                if m_get:
                    arg_id = int(m_get.group(1))
                else:
                    continue
                # Extract the return variable
                return_var = line.split("=")[0].strip()
                stream_index = arg_id - len(inputs) - len(outputs)
                stream_name = streams[stream_index][0]
                current_indent = 6 + (len(line) - len(line.lstrip(" ")))
                with format_code(indent=current_indent):
                    # Acquire the FIFO
                    ele_type = stream_ele_types[stream_name]
                    code += format_str(
                        f"%{stream_name} = aie.objectfifo.acquire @{stream_name}(Consume, 1) : !aie.objectfifosubview<{ele_type}>"
                    )
                    code += format_str(
                        f"%local_{stream_name} = aie.objectfifo.subview.access %{stream_name}[0] : !aie.objectfifosubview<{ele_type}> -> {ele_type}"
                    )
                    # Load the value into a local variable if the element type is scalar
                    if "x" not in ele_type:
                        code += format_str(
                            f"{return_var} = memref.load %local_{stream_name}[] : {ele_type}"
                        )
                    else:
                        # Otherwise, replace the return variable with the local stream variable
                        func_str = func_str.replace(return_var, f"%local_{stream_name}")
                        lines = func_str.splitlines()
                    # Release the FIFO
                    code += format_str(
                        f"aie.objectfifo.release @{stream_name}(Consume, 1)"
                    )
            # Process stream_put
            elif "stream_put" in line:
                # Extract the argument id from the pattern "stream_put(%arg<digits>"
                m_put_id = re.search(r"stream_put\(%arg(\d+)", line)
                if m_put_id:
                    arg_id = int(m_put_id.group(1))
                else:
                    continue
                # Extract the put variable
                search_start = m_put_id.end()
                m_put_var = re.search(r"(%[^)]+)", line[search_start:])
                if m_put_var:
                    put_var = m_put_var.group(1)
                else:
                    continue
                stream_index = arg_id - len(inputs) - len(outputs)
                stream_name = streams[stream_index][0]
                ele_type = stream_ele_types[stream_name]
                current_indent = 6 + (len(line) - len(line.lstrip(" ")))
                with format_code(indent=current_indent):
                    # Acquire the FIFO
                    code += format_str(
                        f"%{stream_name} = aie.objectfifo.acquire @{stream_name}(Produce, 1) : !aie.objectfifosubview<{ele_type}>"
                    )
                    code += format_str(
                        f"%local_{stream_name} = aie.objectfifo.subview.access %{stream_name}[0] : !aie.objectfifosubview<{ele_type}> -> {ele_type}"
                    )
                    # Depending on the element type, either perform a memref.copy or a memref.store
                    if "x" in ele_type:
                        code += format_str(
                            f"memref.copy {put_var}, %local_{stream_name} : {ele_type} to {ele_type}"
                        )
                    else:
                        code += format_str(
                            f"memref.store {put_var}, %local_{stream_name}[] : {ele_type}"
                        )
                    # Release the FIFO
                    code += format_str(
                        f"aie.objectfifo.release @{stream_name}(Produce, 1)"
                    )
            else:
                code += format_str(line, strip=False)
    return code, func_str


def get_memref_type_str(ele_type, shape):
    return f"memref<{'x'.join(map(str, shape))}x{ele_type}>"


def calculate_tensor_access(shape, partition, num_devices=None):
    """
    Calculate the size and stride for tensor access based on shape and partition method.

    Parameters:
    -----------
    shape : tuple
        The shape of the tensor (1D or 2D)
    partition : str
        The partition method for each dimension:
        - 'S': Sharded (distributed across devices)
        - 'R': Replicated (copied to each device)
    num_devices : int or None, optional
        For 1D tensor or SR/RS: total number of devices
        For SS: assumed to be a square number (devices per dimension will be sqrt)

    Returns:
    --------
    tuple
        A tuple containing two lists: (size, stride)
    """
    # Set default num_devices based on partition strategy
    if num_devices is None:
        if partition in ["S", "R", "SR", "RS"]:
            num_devices = 2
        elif partition == "SS":
            num_devices = 4  # 2x2 mesh by default

    # Handle 1D tensor case
    if len(shape) == 1:
        if partition == "S":
            shard_size = shape[0] // num_devices
            size = [1, 1, num_devices, shard_size]
            stride = [0, 0, shard_size, 1]
        elif partition == "R":
            size = [1, num_devices, 1, shape[0]]
            stride = [0, 0, 0, 1]
        return size, stride

    # Handle 2D tensor case
    elif len(shape) == 2:
        if partition == "SS":
            # Both dimensions sharded
            devices_per_dim = int(num_devices**0.5)  # Square mesh of devices
            dim0_shard = shape[0] // devices_per_dim
            dim1_shard = shape[1] // devices_per_dim

            size = [devices_per_dim, devices_per_dim, dim0_shard, dim1_shard]

            # Correct stride calculation for SS
            stride = [
                dim0_shard
                * shape[1],  # Stride between device rows: dim0_shard * full_width
                dim1_shard,  # Stride between device columns: just the shard width
                shape[1],  # Stride between rows within a device: full width
                1,  # Stride between columns within a device
            ]

        elif partition == "SR":
            # First dim sharded, second replicated
            size = [1, num_devices, shape[0] // num_devices, shape[1]]
            stride = [0, shape[0] * shape[1] // num_devices, shape[1], 1]

        elif partition == "RS":
            # First dim replicated, second sharded
            size = [1, num_devices, shape[0], shape[1] // num_devices]
            stride = [0, shape[0] * shape[1] // num_devices, shape[1], 1]

        elif partition == "RR":
            # Both dimensions replicated
            size = [1, num_devices, shape[0], shape[1]]
            stride = [0, 0, shape[1], 1]

        return size, stride


def codegen_aie_mlir(
    mod,
    kernel_func,
    external_kernels,
    stream_info,
):
    """
    Generates MLIR-AIE code with MLIR module and extra information

    Parameters
    ----------
    mod: allo._mlir.ir.Module
        The MLIR module built by allo.

    kernel_func: KernelFunction
        The kernel function object containing the mapping, inputs, and outputs.

    external_kernels: Dict[str, List[str]]
        The external kernels that will be injected into the module.
        The key is the name of the function, and the value is a list of names of the external kernels.

    stream_info: Dict[str, List[Tuple[str, str]]]
        The input and output stream of each kernel.
        The key is the name of the kernel, and the value is a list of tuples.
        The first element in the tuple is the name of the stream, the second element is either 'in' or 'out'.
    """
    # currently only one single kernel
    kernel_name = kernel_func.name
    mapping = kernel_func.mapping
    code = format_str("module {", indent=0)
    num_dt_args = len(kernel_func.dtensors[0])
    mem_tile_size = 2 if num_dt_args > 2 else 1
    device = "npu1_2col" if num_dt_args > 2 else "npu1_1col"
    code += format_str(f"aie.device({device}) {{", indent=2)
    # external functions
    for func in mod.body.operations:
        if (
            isinstance(func, func_d.FuncOp)
            and "sym_visibility" in func.attributes
            and func.attributes["sym_visibility"].value == "private"
        ):
            code += format_str(str(func), indent=4)
    # create tiles
    code += format_str("%tile_shim = aie.tile(0, 0)")
    for mid in range(mem_tile_size):
        code += format_str(f"%tile_mem{mid} = aie.tile({mid}, 1)")
    # number of function declaration except top
    top_func, funcs = get_public_funcs(mod)
    # buf_name_dicts = []
    # create compute tiles and buffers
    func_names = []
    for idx, func in enumerate(funcs):
        func_name = func.attributes["sym_name"].value
        tile_name = f"%tile_comp_{func_name}"
        code += format_str(f"{tile_name} = aie.tile(0, {idx + 2})")
        func_names.append(func_name)
        # buf_dict = {} #TODO: func_buf_dicts[func_id - start]
        # buf_name_dict = {}
        # for i, name in enumerate(buf_dict.keys()):
        #     new_name = f"{tile_name}_buf{i}"
        #     buf_name_dict[name] = new_name
        #     ele_type, shape = buf_dict[name]
        #     str_list = list(map(str, shape))
        #     str_list.append(ele_type)
        #     buf_type = f"memref<{'x'.join(map(str, str_list))}>"
        #     code += format_str(f"{new_name} = aie.buffer({tile_name}) : {buf_type}")
        # buf_name_dicts.append(buf_name_dict)
    # update module and args
    # (global_memref_type, global_shape, [(func_name, local_memref_type0, local_shape0), ...])
    inputs = []
    outputs = []
    for i, (dtype, shape) in enumerate(kernel_func.inputs):
        # take the i-th argument of each kernel function
        dtensors = [
            (
                func_name,
                get_memref_type_str(dt[i].dtype, dt[i].local_shape),
                dt[i].local_shape,
            )
            for func_name, dt in zip(func_names, kernel_func.dtensors)
        ]
        inputs.append((get_memref_type_str(dtype, shape), shape, dtensors))
    for i, (dtype, shape) in enumerate(
        kernel_func.outputs, start=len(kernel_func.inputs)
    ):
        dtensors = [
            (
                func_name,
                get_memref_type_str(dt[i].dtype, dt[i].local_shape),
                dt[i].local_shape,
            )
            for func_name, dt in zip(func_names, kernel_func.dtensors)
        ]
        outputs.append((get_memref_type_str(dtype, shape), shape, dtensors))
    func_strs = list(map(str, funcs))
    # update buffers
    # for func_id, func_str in enumerate(func_strs):
    #     buf_name_dict = buf_name_dicts[func_id]
    #     # remove memref.alloc
    #     pattern_alloc = re.compile(r"^.*memref\.alloc.*\n?", re.MULTILINE)
    #     func_str = re.sub(pattern_alloc, "", func_str)
    #     # replace new buffer name
    #     pattern_boundary = r"(?<![\w.]){old}(?![\w.])"
    #     for name, new_name in buf_name_dict.items():
    #         escaped_name = re.escape(name)
    #         pattern = pattern_boundary.format(old=escaped_name)
    #         func_str = re.sub(pattern, new_name, func_str)
    #     func_strs[func_id] = func_str
    # create input object fifos
    # connect each argument to a separate mem tile
    for arg_id, (global_memref_type, _, dtensors) in enumerate(inputs):
        # depth=2 means double buffer
        # shim tile to mem tile (preserve the original size)
        code += format_str(
            f"aie.objectfifo @in_sh_{kernel_name}_arg{arg_id}(%tile_shim, {{%tile_mem{arg_id}}}, 2 : i32) : !aie.objectfifo<{global_memref_type}>"
        )
        # mem tile to compute tile (partition the tensor)
        in_mem_stride = []
        for func_name, local_memref, local_shape in dtensors:
            code += format_str(
                f"aie.objectfifo @in_{func_name}_arg{arg_id}(%tile_mem{arg_id}, {{%tile_comp_{func_name}}}, 2 : i32) : !aie.objectfifo<{local_memref}>"
            )
            in_mem_stride.append(
                (in_mem_stride[-1] if len(in_mem_stride) > 0 else 0)
                + np.prod(local_shape)
            )
        in_mem_stride.insert(0, 0)
        in_mem_stride = in_mem_stride[:-1]  # remove the last stride
        in_mem_str = ", ".join(
            [f"@in_{func.attributes["sym_name"].value}_arg{arg_id}" for func in funcs]
        )
        # (src_offsets, dst_offsets)
        code += format_str(
            f"aie.objectfifo.link [@in_sh_{kernel_name}_arg{arg_id}] -> [{in_mem_str}]([] {in_mem_stride})"
        )
    # create output object fifos
    for _, (global_memref_type, _, dtensors) in enumerate(outputs):
        # output uses tile_mem0
        out_mem_stride = []
        for func_name, local_memref, local_shape in dtensors:
            code += format_str(
                f"aie.objectfifo @out_{func_name}(%tile_comp_{func_name}, {{%tile_mem0}}, 2 : i32) : !aie.objectfifo<{local_memref}>"
            )
            out_mem_stride.append(
                (out_mem_stride[-1] if len(out_mem_stride) > 0 else 0)
                + np.prod(local_shape)
            )
        out_mem_stride.insert(0, 0)
        out_mem_stride = out_mem_stride[:-1]  # remove the last stride
        code += format_str(
            f"aie.objectfifo @out_sh_{kernel_name}(%tile_mem0, {{%tile_shim}}, 2 : i32) : !aie.objectfifo<{global_memref_type}>"
        )
        out_mem_str = ", ".join(
            [f"@out_{func.attributes["sym_name"].value}" for func in funcs]
        )
        code += format_str(
            f"aie.objectfifo.link [{out_mem_str}] -> [@out_sh_{kernel_name}]({out_mem_stride} [])"
        )
    # create other object fifos from top_func
    stream_in_out = get_stream_in_out(stream_info)
    stream_ele_types = {}
    for op in top_func.entry_block.operations:
        if isinstance(op, allo_d.StreamConstructOp):
            stream_name = op.attributes["name"].value
            if stream_name in stream_in_out:
                in_out = stream_in_out[stream_name]
                stream_type_str = str(op.results.types[0])
                start = stream_type_str.find("<") + 1
                end = stream_type_str.rfind(">")
                type_str, depth_str = stream_type_str[start:end].split(",")
                type_str = type_str.strip()
                if not type_str.startswith("memref"):
                    type_str = f"memref<{type_str}>"
                depth = int(depth_str.strip())
                code += format_str(
                    f"aie.objectfifo @{stream_name}(%tile_comp_{in_out[0]}, {{%tile_comp_{in_out[1]}}}, {depth} : i32) : !aie.objectfifo<{type_str}>"
                )
                stream_ele_types[stream_name] = type_str
    # create core computation
    in_args = []
    out_args = []
    arg_index = 0
    for func_id, func in enumerate(funcs):
        func_str = func_strs[func_id]
        func_name = func.attributes["sym_name"].value
        streams = stream_info[func_name]
        code += format_str(
            f"%core_0_{func_id + 2} = aie.core(%tile_comp_{func_name}) {{"
        )
        with format_code(indent=6):
            code += format_str("%global_c0 = arith.constant 0 : index")
            code += format_str("%global_c1 = arith.constant 1 : index")
            code += format_str(
                "%c9223372036854775807 = arith.constant 9223372036854775807 : index"
            )
            code += format_str(
                "scf.for %arg0 = %global_c0 to %c9223372036854775807 step %global_c1 {"
            )
            with format_code(indent=8):
                # Acquire input fifos
                for arg_id, (global_memref_type, _, dtensors) in enumerate(inputs):
                    dtype = dtensors[func_id][1]
                    code += format_str(
                        f"%fifo{arg_id} = aie.objectfifo.acquire @in_{func_name}_arg{arg_id}(Consume, 1) : !aie.objectfifosubview<{dtype}>"
                    )
                    code += format_str(
                        f"%local{arg_id} = aie.objectfifo.subview.access %fifo{arg_id}[0] : !aie.objectfifosubview<{dtype}> -> {dtype}"
                    )
                    func_str = func_str.replace(f"%arg{arg_id}", f"%local{arg_id}")
                # Acquire output fifos
                for arg_id, (global_memref_type, _, dtensors) in enumerate(
                    outputs, start=len(inputs)
                ):
                    dtype = dtensors[func_id][1]
                    code += format_str(
                        f"%fifo_out = aie.objectfifo.acquire @out_{func_name}(Produce, 1) : !aie.objectfifosubview<{dtype}>"
                    )
                    code += format_str(
                        f"%local_out = aie.objectfifo.subview.access %fifo_out[0] : !aie.objectfifosubview<{dtype}> -> {dtype}"
                    )
                    func_str = func_str.replace(f"%arg{arg_id}", "%local_out")
                # Not sure why call cannot work
                while " call @" in func_str:
                    func_str = func_str.replace(" call @", " func.call @")
                # Main computation
                stream_code, func_str = process_stream_operations(
                    func_str, streams, inputs, outputs, stream_ele_types
                )
                code += stream_code
                # Release input fifos
                for arg_id in range(len(inputs)):
                    code += format_str(
                        f"aie.objectfifo.release @in_{func_name}_arg{arg_id}(Consume, 1)"
                    )
                # Release output fifos
                for arg_id in range(len(inputs), len(inputs) + len(outputs)):
                    code += format_str(
                        f"aie.objectfifo.release @out_{func_name}(Produce, 1)"
                    )
            code += format_str("}")
            code += format_str("aie.end")
        code += "    }"
        if len(external_kernels[f"{func_name}"]) > 0:
            code += ' {link_with = "external.o"}\n'
        else:
            code += "\n"
    for arg_id, (global_memref_type, _, _) in enumerate(inputs):
        in_args.append(f"%arg{arg_index}: {global_memref_type}")
    for arg_id, (global_memref_type, _, _) in enumerate(outputs, start=len(inputs)):
        out_args.append(f"%arg{arg_index}: {global_memref_type}")
        arg_index += 1
    # create dma transfer from off-chip mem to shim tile
    code += format_str(
        f"aiex.runtime_sequence({",".join(in_args)}, {",".join(out_args)}) {{"
    )
    with format_code(indent=6):
        for arg_id, (global_memref_type, global_shape, _) in enumerate(inputs):
            # (x, y, memref[offset][size][stride])
            # issue_token: MM2S-false, S2MM-true
            dtensor = kernel_func.dtensors[0][arg_id]
            size, stride = calculate_tensor_access(
                global_shape, dtensor.placement, dtensor.comm_size
            )
            code += format_str(
                f"aiex.npu.dma_memcpy_nd(0, 0, %arg{arg_id}[0, 0, 0, 0]{size}{stride}) {{id = {arg_id + 1} : i64, issue_token = true, metadata = @in_sh_{kernel_name}_arg{arg_id}}} : {global_memref_type}"
            )
        for arg_id, (global_memref_type, global_shape, _) in enumerate(
            outputs, start=len(inputs)
        ):
            dtensor = kernel_func.dtensors[0][arg_id]
            size, stride = calculate_tensor_access(
                global_shape, dtensor.placement, dtensor.comm_size
            )
            code += format_str(
                f"aiex.npu.dma_memcpy_nd(0, 0, %arg{arg_id}[0, 0, 0, 0]{size}{stride}) {{id = 0 : i64, metadata = @out_sh_{kernel_name}}} : {global_memref_type}"
            )
            arg_index += 1
        for arg_id in range(len(inputs)):
            code += format_str(
                f"aiex.npu.dma_wait {{symbol = @in_sh_{kernel_name}_arg{arg_id}}}"
            )
        code += format_str(f"aiex.npu.dma_wait {{symbol = @out_sh_{kernel_name}}}")
    code += format_str("}")
    code += format_str("}", indent=2)
    code += "}"
    return code


def update_func_op_arg_types(func_op, inputs, outputs, dtensors, enable_tensor):
    inputs_outputs = inputs + outputs
    new_input_types = []
    with func_op.context, Location.unknown():
        for arg_id, (_, dtensor) in enumerate(zip(inputs_outputs, dtensors)):
            elem_ty = get_element_type_from_str(dtensor.dtype, func_op.context)
            shape = dtensor.local_shape
            memref_ty = (
                RankedTensorType.get(shape, elem_ty)
                if enable_tensor
                else MemRefType.get(shape, elem_ty)
            )
            new_input_types.append(memref_ty)
        new_func_type = FunctionType.get(
            new_input_types, func_op.function_type.value.results, func_op.context
        )
        new_type = TypeAttr.get(new_func_type, func_op.context)
        func_op.operation.attributes["function_type"] = new_type
        entry_block = func_op.entry_block
        for arg_id, block_arg in enumerate(entry_block.arguments):
            if arg_id < len(new_input_types):
                block_arg.set_type(new_input_types[arg_id])
        op_to_remove = []
        for op in func_op.regions[0].blocks[0].operations:
            if op.operation.name == "memref.subview":
                op.result.replace_all_uses_with(op.operands[0])
                op_to_remove.append(op)
        for op in op_to_remove:
            op.erase()


def lower_tensor_to_memref(mod, enable_tensor):
    passes = (
        [
            # "linalg-generalize-named-ops",
            # "linalg-fuse-elementwise-ops",
            "one-shot-bufferize{bufferize-function-boundaries function-boundary-type-conversion=identity-layout-map}",
            "func.func(convert-linalg-to-affine-loops),lower-affine",
        ]
        if enable_tensor
        else [
            # "linalg-generalize-named-ops",
            # "linalg-fuse-elementwise-ops",
            "func.func(convert-linalg-to-affine-loops),lower-affine",
        ]
    )
    pipeline = f'builtin.module({",".join(passes)})'
    with mod.context:
        mlir_pass_manager.parse(pipeline).run(mod.operation)


def record_local_buffer(mod, kernel_index_ranges):
    kernel_func_buf_dicts = {}
    _, funcs = get_public_funcs(mod)
    for kernel_name, (start, end) in kernel_index_ranges.items():
        func_buf_dicts = []
        for func_id in range(start, end):
            func = funcs[func_id]
            buf_dict = {}
            ops_stack = []
            for block in func.regions[0].blocks:
                ops_stack.extend(block.operations)
            while ops_stack:
                op = ops_stack.pop()
                if op.operation.name == "memref.alloc":
                    name = op.result.get_name()
                    dtype, shape = get_dtype_and_shape_from_type(op.result.type)
                    buf_dict[name] = (dtype, shape)
                for region in op.regions:
                    for block in region.blocks:
                        ops_stack.extend(block.operations)
            func_buf_dicts.append(buf_dict)
        kernel_func_buf_dicts[kernel_name] = func_buf_dicts
    return kernel_func_buf_dicts


def parse_mlir_to_kernel_function(module):
    """
    Parse an MLIR module to extract kernel function information

    Args:
        module: The MLIR module

    Returns:
        KernelFunction: A KernelFunction object with extracted information
    """
    # Find the top function and kernel functions
    top_func = None
    kernel_funcs = []

    for op in module.body.operations:
        if isinstance(op, func_d.FuncOp):
            func_name = op.name.value

            if func_name == "top":
                top_func = op
            elif "_" in func_name:
                kernel_funcs.append(op)

    if not top_func:
        raise ValueError("No top function found in the MLIR module")

    if not kernel_funcs:
        raise ValueError("No kernel functions found in the MLIR module")

    # Extract base kernel name and mapping
    first_kernel = kernel_funcs[0].name.value
    base_name = first_kernel.split("_")[0]

    # Find maximum indices for each dimension
    mapping_indices = []
    for op in kernel_funcs:
        func_name = op.name.value
        if func_name.startswith(base_name):
            parts = func_name[len(base_name) + 1 :].split("_")
            indices = [int(idx) for idx in parts]

            # Expand mapping_indices if needed
            while len(mapping_indices) < len(indices):
                mapping_indices.append(-1)

            # Update maximum values
            for i, idx in enumerate(indices):
                mapping_indices[i] = max(mapping_indices[i], idx)

    # Calculate dimensions (max index + 1 in each dimension)
    mapping = [idx + 1 for idx in mapping_indices]

    # Use a representative kernel function to analyze access patterns
    # Usually all kernels have the same input/output pattern
    representative_kernel = kernel_funcs[0]
    input_indices, output_indices = analyze_read_write_patterns(representative_kernel)

    # Parse input and output types based on the access patterns
    inputs = []
    outputs = []

    # Get the top function arguments
    for i, arg in enumerate(top_func.arguments):
        # Get the type of the argument
        arg_type = arg.type

        # Check if it's a memref type
        if MemRefType.isinstance(arg_type):
            memref_type = MemRefType(arg_type)

            # Get shape and element type
            shape = memref_type.shape
            element_type = memref_type.element_type

            # Extract dtype (e.g., i32)
            dtype = str(element_type)

            # Determine if this is an input or output based on access patterns
            # Using proportional mapping from kernel args to top function args
            kernel_arg_count = len(representative_kernel.arguments)

            # Simple proportional mapping - may need refinement for complex cases
            kernel_arg_index = min(i, kernel_arg_count - 1)

            if kernel_arg_index in input_indices:
                inputs.append((dtype, list(shape)))
            if kernel_arg_index in output_indices:
                outputs.append((dtype, list(shape)))

    # Create and return the KernelFunction
    kernel_func = KernelFunction(base_name, mapping, inputs, outputs)

    # Set the MLIR functions
    kernel_func.set_mlir_funcs(kernel_funcs)
    return kernel_func


def create_dtensors_from_kernel(kernel_func, func_op):
    """
    Analyze the MLIR function and create DTensor objects for each argument,
    inferring placement based on subview operations.

    Args:
        kernel_func (KernelFunction): The kernel function containing mapping information
        func_op: The MLIR function operation to analyze

    Returns:
        list: List of DTensor objects for each argument
    """
    # Extract information from the kernel function
    mapping = kernel_func.mapping  # e.g., [2, 2] for a 2x2 grid
    comm_size = 1
    for dim in mapping:
        comm_size *= dim

    # Get rank from function name (e.g., "gemm_0_1" -> rank 1)
    func_name = str(func_op.attributes["sym_name"]).strip('"')
    coords = func_name.split("_")[1:]  # Extract coordinates, e.g., ["0", "1"]
    rank = 0
    for i, coord in enumerate(coords):
        rank += int(coord) * (mapping[i + 1 :] + [1]).pop(0)

    # Calculate rank coordinates
    rank_coords = []
    rank_copy = rank
    for dim_size in reversed(mapping):
        rank_coords.insert(0, rank_copy % dim_size)
        rank_copy //= dim_size

    # Create DTensor objects for each argument
    dtensors = []
    for i, arg in enumerate(func_op.arguments):
        # Get memref shape and type from argument
        arg_type = arg.type
        shape = []
        dtype = None

        # Extract the shape and type from the argument
        arg_type_str = str(arg_type)
        if arg_type_str.startswith("memref<"):
            # Extract the part between memref< and >
            inner_type = arg_type_str[len("memref<") : -1]
            # Parse shape and data type
            parts = inner_type.split("x")

            # Extract dimensions from each part
            for j in range(len(parts) - 1):
                shape.append(int(parts[j]))

            # Last part contains dimension and data type
            last_part = parts[-1]
            dim_end = 0
            while dim_end < len(last_part) and last_part[dim_end].isdigit():
                dim_end += 1

            if dim_end > 0:
                shape.append(int(last_part[:dim_end]))

            # Extract data type
            dtype = last_part[dim_end:]

        # Create DTensor object
        dtensor = DTensor(rank, comm_size, shape, dtype)
        dtensors.append(dtensor)

    # Analyze subview operations to determine the actual tensor partitioning
    subviews = {}  # Maps arg index to (offset, size) tuples

    # Find all subview operations in the function
    def collect_subviews(block):
        for op in block.operations:
            op_name = str(op.operation.name)
            if op_name == "memref.subview":
                if len(op.operands) >= 1:
                    source = op.operands[0]

                    # If source is a block argument, record its subview information
                    if BlockArgument.isinstance(source):
                        arg_num = BlockArgument(source).arg_number

                        # Extract offset and size from operation string
                        op_str = str(op)

                        # Parse offset and size parameters from the subview operation
                        offset = []
                        size = []

                        # Extract parameters using regex
                        import re

                        subview_pattern = (
                            r"memref\.subview\s+%[^[]+\[([^\]]+)\]\s+\[([^\]]+)\]"
                        )
                        match = re.search(subview_pattern, op_str)

                        if match:
                            # Extract offset
                            offset_str = match.group(1)
                            offset = [int(o.strip()) for o in offset_str.split(",")]

                            # Extract size
                            size_str = match.group(2)
                            size = [int(s.strip()) for s in size_str.split(",")]

                            # Store the subview information
                            subviews[arg_num] = (offset, size)

            # Recursively process nested regions
            for region in op.regions:
                for block in region.blocks:
                    collect_subviews(block)

    # Collect subview information
    for block in func_op.body.blocks:
        collect_subviews(block)

    # Infer placement based on subview analysis and rank coordinates
    for i, dtensor in enumerate(dtensors):
        if i in subviews:
            offset, size = subviews[i]
            dtensor.set_subview(offset, size)

            # Determine placement based on how the tensor is partitioned
            placement = ""
            for dim in range(len(dtensor.shape)):
                # If this dimension is fully utilized (size equals global shape), it's Replicated
                # Otherwise, it's Sharded
                dim_size = size[dim] if dim < len(size) else dtensor.shape[dim]
                global_dim_size = dtensor.shape[dim]

                if dim_size == global_dim_size:
                    placement += "R"  # Replicated dimension
                else:
                    placement += "S"  # Sharded dimension

            dtensor.set_placement(placement)

    return dtensors


class AIEModule:
    def __init__(
        self,
        module,
        top_func_name,
        project,
        kernel_mappings,
        enable_tensor,
        stream_info,
    ):
        self.module = module
        self.top_func_name = top_func_name
        self.project = project
        self.module = module
        self.kernel_mappings = kernel_mappings
        self.enable_tensor = enable_tensor
        self.stream_info = stream_info

    def build(self):
        assert "MLIR_AIE_INSTALL_DIR" in os.environ, "Please set MLIR_AIE_INSTALL_DIR"
        assert "PEANO_INSTALL_DIR" in os.environ, "Please set PEANO_INSTALL_DIR"
        kernel_func = parse_mlir_to_kernel_function(self.module)
        for i, func_op in enumerate(kernel_func.funcs):
            kernel_func.set_dtensors(
                create_dtensors_from_kernel(kernel_func, func_op), i
            )
            update_func_op_arg_types(
                func_op,
                kernel_func.inputs,
                kernel_func.outputs,
                kernel_func.dtensors[i],
                self.enable_tensor,
            )
        print(self.module)
        external_kernels = inject_aie_kernels(self.module)
        with open(
            os.path.join(self.project, "original.mlir"), "w", encoding="utf-8"
        ) as f:
            f.write(str(self.module))
        lower_tensor_to_memref(self.module, self.enable_tensor)
        print(self.module)
        # kernel_func_buf_dicts = record_local_buffer(
        #     self.module, self.kernel_index_ranges
        # )
        code = codegen_aie_mlir(
            self.module,
            kernel_func,
            external_kernels,
            self.stream_info,
        )
        os.makedirs(os.path.join(self.project, "build"), exist_ok=True)
        with open(os.path.join(self.project, "top.mlir"), "w", encoding="utf-8") as f:
            f.write(code)
        sys.exit()
        # compile external kernels
        kernel_code, generated_kernels = codegen_external_kernels(external_kernels)
        if len(generated_kernels) > 0:
            with open(
                os.path.join(self.project, "external.cc"), "w", encoding="utf-8"
            ) as f:
                f.write(kernel_code)
            path = os.path.join(os.path.dirname(__file__), "aie_kernels")
            cmd = f"cd {self.project} && $PEANO_INSTALL_DIR/bin/clang++ -O2 -v -std=c++20 --target=aie2-none-unknown-elf -Wno-parentheses -Wno-attributes -Wno-macro-redefined -DNDEBUG -I $(dirname $(which aie-opt))/../include -I $MLIR_AIE_INSTALL_DIR/../aie_kernels/aie2 -c external.cc -o external.o"
            process = subprocess.Popen(cmd, shell=True)
            process.wait()
            if process.returncode != 0:
                raise RuntimeError("Failed to compile external kernels.")
        # build mlir-aie
        cmd = f"cd {self.project} && PYTHONPATH=$MLIR_AIE_INSTALL_DIR/python aiecc.py --aie-generate-cdo --aie-generate-npu --no-compile-host --no-xchesscc --no-xbridge --xclbin-name=build/final.xclbin --npu-insts-name=insts.txt top.mlir"
        process = subprocess.Popen(cmd, shell=True)
        process.wait()
        if process.returncode != 0:
            raise RuntimeError("Failed to compile the MLIR-AIE code")
        path = os.path.dirname(__file__)
        path = os.path.join(path, "../harness/aie")
        os.system(f"cp -r {path}/* {self.project}")
        host_code = codegen_host(self.kernel_inputs, self.kernel_outputs)
        with open(os.path.join(self.project, "test.cpp"), "w", encoding="utf-8") as f:
            f.write(host_code)
        cmd = f"cd {self.project}/build && cmake .. -DTARGET_NAME=top -DMLIR_AIE_DIR=$MLIR_AIE_INSTALL_DIR/.. && cmake --build . --config Release"
        process = subprocess.Popen(cmd, shell=True)
        process.wait()
        if process.returncode != 0:
            raise RuntimeError("Failed to build AIE project.")
        return self

    def __call__(self, *args):
        # suppose the last argument is output
        for i, arg in enumerate(args[:-1]):
            with open(
                os.path.join(self.project, f"input{i}.data"), "w", encoding="utf-8"
            ) as f:
                f.write("\n".join([str(i) for i in arg.flatten()]))
        cmd = f"cd {self.project} && ./build/top -x build/final.xclbin -i insts.txt -k MLIR_AIE"
        process = subprocess.Popen(cmd, shell=True)
        process.wait()
        if process.returncode != 0:
            raise RuntimeError("Failed to execute AIE code.")
        # TODO: need to complete multiple outputs rules
        result = read_tensor_from_file(
            list(self.kernel_outputs.values())[-1][0][0],
            args[-1].shape,
            f"{self.project}/output.data",
        )
        args[-1][:] = result
