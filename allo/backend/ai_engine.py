# Copyright Allo authors. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0
# mlir-aie commit: 8329b6
# pylint: disable=bad-builtin, no-name-in-module, too-many-branches, too-many-nested-blocks, consider-using-with, cell-var-from-loop


import os
import subprocess
import re
from collections import defaultdict, namedtuple
import numpy as np
from .._mlir.ir import (
    MemRefType,
    Location,
    InsertionPoint,
    FlatSymbolRefAttr,
    StringAttr,
)
from .._mlir.dialects import (
    allo as allo_d,
    func as func_d,
)
from .._mlir.passmanager import PassManager as mlir_pass_manager

from .vitis import read_tensor_from_file
from ..utils import get_dtype_and_shape_from_type
from .utils import format_str, format_code
from .vitis import ctype_map
from ..passes import analyze_read_write_patterns


host_header = """
//=============================================================================
// Auto generated by Allo
//=============================================================================

#include <boost/program_options.hpp>
#include <cstdint>
#include <fstream>
#include <iostream>
#include <sstream>
#include <string>
#include <vector>

#include "xrt/xrt_bo.h"
#include "xrt/xrt_device.h"
#include "xrt/xrt_kernel.h"

#include "test_utils.h"

namespace po = boost::program_options;

int main(int argc, const char *argv[]) {

  // ------------------------------------------------------
  // Parse program arguments
  // ------------------------------------------------------
  po::options_description desc("Allowed options");
  po::variables_map vm;
  test_utils::add_default_options(desc);

  test_utils::parse_options(argc, argv, desc, vm);
  int verbosity = vm["verbosity"].as<int>();
  int do_verify = vm["verify"].as<bool>();
  int n_iterations = vm["iters"].as<int>();
  int n_warmup_iterations = vm["warmup"].as<int>();
  int trace_size = vm["trace_sz"].as<int>();

  // Load instruction sequence
  std::vector<uint32_t> instr_v =
      test_utils::load_instr_sequence(vm["instr"].as<std::string>());
  if (verbosity >= 1)
    std::cout << "Sequence instr count: " << instr_v.size() << "\\n";

  // ------------------------------------------------------
  // Get device, load the xclbin & kernel and register them
  // ------------------------------------------------------
  // Get a device handle
  unsigned int device_index = 0;
  auto device = xrt::device(device_index);

  // Load the xclbin
  if (verbosity >= 1)
    std::cout << "Loading xclbin: " << vm["xclbin"].as<std::string>() << "\\n";
  auto xclbin = xrt::xclbin(vm["xclbin"].as<std::string>());

  // Load the kernel
  if (verbosity >= 1)
    std::cout << "Kernel opcode: " << vm["kernel"].as<std::string>() << "\\n";
  std::string Node = vm["kernel"].as<std::string>();

  // Get the kernel from the xclbin
  auto xkernels = xclbin.get_kernels();
  auto xkernel = *std::find_if(xkernels.begin(), xkernels.end(),
                               [Node, verbosity](xrt::xclbin::kernel &k) {
                                 auto name = k.get_name();
                                 if (verbosity >= 1) {
                                   std::cout << "Name: " << name << std::endl;
                                 }
                                 return name.rfind(Node, 0) == 0;
                               });
  auto kernelName = xkernel.get_name();

  // Register xclbin
  if (verbosity >= 1)
    std::cout << "Registering xclbin: " << vm["xclbin"].as<std::string>()
              << "\\n";
  device.register_xclbin(xclbin);

  // Get a hardware context
  if (verbosity >= 1)
    std::cout << "Getting hardware context.\\n";
  xrt::hw_context context(device, xclbin.get_uuid());

  // Get a kernel handle
  if (verbosity >= 1)
    std::cout << "Getting handle to kernel:" << kernelName << "\\n";
  auto kernel = xrt::kernel(context, kernelName);

  // ------------------------------------------------------
  // Initialize input/ output buffer sizes and sync them
  // ------------------------------------------------------
  auto bo_instr = xrt::bo(device, instr_v.size() * sizeof(int),
                          XCL_BO_FLAGS_CACHEABLE, kernel.group_id(1));
  void *bufInstr = bo_instr.map<void *>();
  memcpy(bufInstr, instr_v.data(), instr_v.size() * sizeof(int));

  std::ofstream ofile("output.data");
  if (!ofile.is_open()) {
      std::cerr << "Error: Could not open output file.\\n";
      return 1;
  }

"""

file_close_str = """  ofile.close();
  if (verbosity >= 1)
    std::cout << "Array has been written to output.data.\\n";
  return 0;
}
"""


def codegen_host(inputs, outputs):
    code = host_header
    with format_code(indent=2):
        # write input data
        for i, dtensor in enumerate(inputs):
            shape = dtensor.shape
            dtype = ctype_map[str(dtensor.dtype)]
            code += format_str(f'std::ifstream ifile{i}("input{i}.data");')
            code += format_str(f"if (!ifile{i}.is_open()) {{")
            code += format_str(
                '  std::cerr << "Error: Could not open input file.\\n";', strip=False
            )
            code += format_str("  return 1;", strip=False)
            code += format_str("}")
            size = np.prod(shape)
            code += format_str(
                f"auto bo_in{i} = xrt::bo(device, {size} * sizeof({dtype}),"
            )
            with format_code(indent=24):
                code += format_str(
                    f"XRT_BO_FLAGS_HOST_ONLY, kernel.group_id({i + 3}));"
                )
            code += format_str(f"{dtype} *bufIn{i} = bo_in{i}.map<{dtype} *>();")
            code += format_str(f"std::vector<{dtype}> srcVec{i};")
            code += format_str(f"for (int i = 0; i < {size}; i++) {{")
            with format_code(indent=4):
                code += format_str(f"{dtype} num;")
                code += format_str(f"ifile{i} >> num;")
                code += format_str(f"srcVec{i}.push_back(num);")
            code += format_str("}")
            code += format_str(
                f"memcpy(bufIn{i}, srcVec{i}.data(), (srcVec{i}.size() * sizeof({dtype})));"
            )
        for i, dtensor in enumerate(outputs):
            shape = dtensor.shape
            dtype = ctype_map[str(dtensor.dtype)]
            out_size = np.prod(shape)
            code += format_str(
                f"\nauto bo_out{i} = xrt::bo(device, {out_size} * sizeof({dtype}),",
                strip=False,
            )
            with format_code(indent=24):
                code += format_str(
                    f"XRT_BO_FLAGS_HOST_ONLY, kernel.group_id({len(inputs) + 2 + i}));"
                )
        code += format_str("if (verbosity >= 1)")
        code += format_str(
            '  std::cout << "Writing data into buffer objects.\\n";', strip=False
        )
        code += format_str("\nbo_instr.sync(XCL_BO_SYNC_BO_TO_DEVICE);", strip=False)
        for i in range(len(inputs)):
            code += format_str(f"bo_in{i}.sync(XCL_BO_SYNC_BO_TO_DEVICE);")
        # run kernels
        code += format_str("if (verbosity >= 1)")
        code += format_str('  std::cout << "Running Kernel.\\n";', strip=False)
        code += format_str(
            "\nauto start = std::chrono::high_resolution_clock::now();", strip=False
        )
        code += format_str("unsigned int opcode = 3;", strip=False)
        inbufs = ", ".join([f"bo_in{i}" for i in range(len(inputs))])
        outbufs = ", ".join([f"bo_out{i}" for i in range(len(outputs))])
        code += format_str("// gid: (opcode, instr, instr_size, ...)")
        code += format_str(
            f"auto run = kernel(opcode, bo_instr, instr_v.size(), {inbufs}, {outbufs});"
        )
        code += format_str("run.wait();")
        code += format_str(
            "\nauto end = std::chrono::high_resolution_clock::now();", strip=False
        )
        code += format_str(
            "float npu_time = std::chrono::duration_cast<std::chrono::microseconds>(end - start).count();"
        )
        code += format_str(
            'std::cout << "NPU execution time: " << npu_time << "us\\n";'
        )
        # get results
        for i, dtensor in enumerate(outputs):
            shape = dtensor.shape
            dtype = ctype_map[str(dtensor.dtype)]
            out_size = np.prod(shape)
            code += format_str(
                f"\nbo_out{i}.sync(XCL_BO_SYNC_BO_FROM_DEVICE);", strip=False
            )
            code += format_str(f"{dtype} *bufOut{i} = bo_out{i}.map<{dtype} *>();")
            code += format_str(f"for (uint32_t i = 0; i < {out_size}; i++) {{")
            code += format_str(f'  ofile << *(bufOut{i} + i) << "\\n";', strip=False)
            code += format_str("}")
        code += format_str("\n// Close files", strip=False)
        for i in range(len(inputs)):
            code += format_str(f"ifile{i}.close();")
        code += file_close_str
    return code


def get_stream_in_out(stream_info):
    """
    Computes the mapping of FIFO names to their producer (output) and consumer (input) cores.

    Parameters
    ----------
    stream_info (Dict[int, List[Tuple[str, str]]]):
        A dictionary where the key is a core ID (int), and the value is a list of tuples.
        Each tuple contains:
        - fifo_name (str): The name of the FIFO.
        - direction (str): The direction of data flow, either "in" (consumer) or "out" (producer).

    Returns
    -------
    Dict[str, Tuple[Optional[int], Optional[int]]]]:
        A dictionary where the key is a FIFO name, and the value is a tuple:
        - The first element is the producer function and the second element is the consumer function.
    """
    stream_in_out = {}
    for core, fifos in stream_info.items():
        for fifo_name, direction in fifos:
            if fifo_name not in stream_in_out:
                stream_in_out[fifo_name] = (None, None)
            if direction == "in":
                stream_in_out[fifo_name] = (stream_in_out[fifo_name][0], core)
            elif direction == "out":
                stream_in_out[fifo_name] = (core, stream_in_out[fifo_name][1])
    return stream_in_out


def get_public_funcs(mod):
    funcs = []
    top_func = None
    for func in mod.body.operations:
        if isinstance(func, func_d.FuncOp) and (
            "sym_visibility" not in func.attributes
            or func.attributes["sym_visibility"].value != "private"
        ):
            if func.attributes["sym_name"].value == "top":
                top_func = func
            else:
                funcs.append(func)
    return top_func, funcs


def inject_aie_kernels(mod):
    external_kernels = {}
    injected_kernels = set()
    with mod.context, Location.unknown():
        for func in mod.body.operations:
            external_kernels[func.attributes["sym_name"].value] = []
            for block in func.regions[0].blocks:
                for op in block.operations:
                    if (
                        (
                            op.operation.name in {"linalg.add", "linalg.mul"}
                            and len(MemRefType(op.inputs[0].type).shape) == 1
                        )
                        or op.operation.name == "linalg.matmul"
                        or (
                            "op_name" in op.attributes
                            and "init_zero" in op.attributes["op_name"].value
                        )
                    ):
                        if op.operation.name in {
                            "linalg.add",
                            "linalg.mul",
                            "linalg.matmul",
                        }:
                            op_name = op.operation.name.split(".")[1]
                            # Inject AIE kernel
                            func_type = func_d.FunctionType.get(
                                [
                                    op.inputs[0].type,
                                    op.inputs[1].type,
                                    op.outputs[0].type,
                                ],
                                [],
                            )
                            dtype = str(op.inputs[0].type.element_type)
                            shape = MemRefType(op.inputs[0].type).shape
                            if op.operation.name in {"linalg.add", "linalg.mul"}:
                                kernel_name = f"{op_name}_{dtype}_vector"
                                external_kernels[
                                    func.attributes["sym_name"].value
                                ].append((op_name, dtype, shape))
                            else:  # linalg.matmul
                                M, K = MemRefType(op.inputs[0].type).shape
                                _, N = MemRefType(op.inputs[1].type).shape
                                out_dtype = str(op.outputs[0].type.element_type)
                                if (dtype, out_dtype) not in [
                                    ("i8", "i8"),
                                    ("i16", "i16"),
                                    ("i16", "i32"),
                                    ("bf16", "bf16"),
                                    ("bf16", "f32"),
                                ]:
                                    # f"Unsupported in_dtype {dtype} and out_dtype {out_dtype} pair"
                                    continue
                                kernel_name = f"matmul_scalar_{dtype}_{out_dtype}"
                                external_kernels[
                                    func.attributes["sym_name"].value
                                ].append((op_name, dtype, out_dtype, M, N, K))
                            func_d.CallOp(
                                [],
                                FlatSymbolRefAttr.get(kernel_name),
                                [op.inputs[0], op.inputs[1], op.outputs[0]],
                                ip=InsertionPoint(op),
                            )
                        else:  # linalg.fill init_zero
                            op_name = "zero"
                            func_type = func_d.FunctionType.get(
                                [op.outputs[0].type], []
                            )
                            dtype = str(op.outputs[0].type.element_type)
                            shape = MemRefType(op.outputs[0].type).shape
                            kernel_name = f"zero_{dtype}_vector"
                            external_kernels[func.attributes["sym_name"].value].append(
                                (op_name, dtype, shape)
                            )
                            func_d.CallOp(
                                [],
                                FlatSymbolRefAttr.get(kernel_name),
                                [op.outputs[0]],
                                ip=InsertionPoint(op),
                            )
                        op.erase()
                        if kernel_name in injected_kernels:
                            continue
                        injected_kernels.add(kernel_name)
                        kernel = func_d.FuncOp(
                            kernel_name,
                            func_type,
                            ip=InsertionPoint(func),
                        )
                        kernel.attributes["sym_visibility"] = StringAttr.get("private")
    return external_kernels


def codegen_external_kernels(external_kernels):
    code = ""
    code += "// External kernels generated by Allo\n\n"
    code += "#include <stdint.h>\n"
    code += "#include <stdio.h>\n"
    code += "#include <stdlib.h>\n"
    code += "#include <type_traits>\n"
    code += "#include <aie_api/aie.hpp>\n\n"
    generated_kernels = {}
    kernel_code = ""
    for _, kernel_lst in external_kernels.items():
        for items in kernel_lst:
            kernel, dtype = items[0], items[1]
            if kernel in generated_kernels:
                continue
            ctype = ctype_map[dtype]
            if "bfloat" in ctype:
                ctype = "bfloat16"
            if kernel == "matmul":
                pass
            elif kernel == "zero":
                dtype, shape = items[1], items[2]
                kernel_code += f"void zero_{dtype}_vector"
                kernel_code += f"({ctype} *C_out)"
                kernel_code += " {\n"
                kernel_code += f"  zero_vectorized<{ctype}, {shape[0]}, {shape[1] if len(shape) == 2 else 1}>(C_out);\n"
                kernel_code += "}\n\n"
            else:
                kernel, dtype, shape = items
                kernel_code += f"void {kernel}_{dtype}_vector"
                kernel_code += f"({ctype} *A_in, {ctype} *B_in, {ctype} *C_out)"
                kernel_code += " {\n"
                kernel_code += f"  eltwise_v{kernel}<{ctype}, {ctype}, {np.prod(shape)}>(A_in, B_in, C_out);\n"
                kernel_code += "}\n\n"
            generated_kernels[kernel] = items
    for kernel, items in generated_kernels.items():
        match kernel:
            case "add":
                code += '#include "add.cc"\n'
            case "mul":
                code += '#include "mul.cc"\n'
            case "matmul":
                _, dtype, out_dtype, M, N, K = items
                code += f"#define DIM_M {M}\n"
                code += f"#define DIM_N {N}\n"
                code += f"#define DIM_K {K}\n"
                code += f"#define {dtype}_{out_dtype}_ONLY\n"
                code += '#include "mm.cc"\n'
            case "zero":
                code += '#include "zero.cc"\n'
    code += '\nextern "C" {\n\n'
    code += kernel_code
    code += '} // extern "C"\n'
    return code, generated_kernels


def process_stream_operations(func_str, streams, start_id, stream_ele_types):
    """
    Process a function string by replacing stream_get and stream_put calls with
    corresponding formatted FIFO code.

    Parameters
    ----------
        func_str: str
            The input function string to be processed.
        streams: List[Tuple]
            Each stream is a tuple/list where the first element is the stream name.
        start_id: int
            The starting ID for the streams, used to map the argument IDs to stream indices.
        stream_ele_types: Dict
            Dictionary mapping stream names to their element types.

    Returns
    -------
        str: The resulting formatted code.
    """
    code = ""
    with format_code(indent=6):
        lines = func_str.splitlines()
        for i in range(1, len(lines) - 2):
            line = lines[i]
            # Process stream_get
            if "stream_get" in line:
                # extract the argument id from the pattern "stream_get(%arg<digits>"
                m_get = re.search(r"stream_get\(%arg(\d+)", line)
                if m_get:
                    arg_id = int(m_get.group(1))
                else:
                    continue
                # Extract the return variable
                return_var = line.split("=")[0].strip()
                stream_index = arg_id - start_id
                stream_name = streams[stream_index][0]
                current_indent = 6 + (len(line) - len(line.lstrip(" ")))
                with format_code(indent=current_indent):
                    # Acquire the FIFO
                    ele_type = stream_ele_types[stream_name]
                    code += format_str(
                        f"%fifo_{stream_name} = aie.objectfifo.acquire @{stream_name}(Consume, 1) : !aie.objectfifosubview<{ele_type}>"
                    )
                    code += format_str(
                        f"%local_{stream_name} = aie.objectfifo.subview.access %fifo_{stream_name}[0] : !aie.objectfifosubview<{ele_type}> -> {ele_type}"
                    )
                    # Load the value into a local variable if the element type is scalar
                    if "x" not in ele_type:
                        code += format_str(
                            f"{return_var} = memref.load %local_{stream_name}[] : {ele_type}"
                        )
                    else:
                        # Otherwise, replace the return variable with the local stream variable
                        func_str = func_str.replace(return_var, f"%local_{stream_name}")
                        lines = func_str.splitlines()
                    # Release the FIFO
                    code += format_str(
                        f"aie.objectfifo.release @{stream_name}(Consume, 1)"
                    )
            # Process stream_put
            elif "stream_put" in line:
                # Extract the argument id from the pattern "stream_put(%arg<digits>"
                m_put_id = re.search(r"stream_put\(%arg(\d+)", line)
                if m_put_id:
                    arg_id = int(m_put_id.group(1))
                else:
                    continue
                # Extract the put variable
                search_start = m_put_id.end()
                m_put_var = re.search(r"(%[^)]+)", line[search_start:])
                if m_put_var:
                    put_var = m_put_var.group(1)
                else:
                    continue
                stream_index = arg_id - start_id
                stream_name = streams[stream_index][0]
                ele_type = stream_ele_types[stream_name]
                current_indent = 6 + (len(line) - len(line.lstrip(" ")))
                with format_code(indent=current_indent):
                    # Acquire the FIFO
                    code += format_str(
                        f"%fifo_{stream_name} = aie.objectfifo.acquire @{stream_name}(Produce, 1) : !aie.objectfifosubview<{ele_type}>"
                    )
                    code += format_str(
                        f"%local_{stream_name} = aie.objectfifo.subview.access %fifo_{stream_name}[0] : !aie.objectfifosubview<{ele_type}> -> {ele_type}"
                    )
                    # Depending on the element type, either perform a memref.copy or a memref.store
                    if "x" in ele_type:
                        code += format_str(
                            f"memref.copy {put_var}, %local_{stream_name} : {ele_type} to {ele_type}"
                        )
                    else:
                        code += format_str(
                            f"memref.store {put_var}, %local_{stream_name}[] : {ele_type}"
                        )
                    # Release the FIFO
                    code += format_str(
                        f"aie.objectfifo.release @{stream_name}(Produce, 1)"
                    )
            else:
                code += format_str(line, strip=False)
    return code, func_str


def get_memref_type_str(ele_type, shape):
    return f"memref<{'x'.join(map(str, shape))}x{ele_type}>"


def calculate_tensor_access(shape, partition, device_mesh):
    """
    Calculate the size and stride for tensor access based on shape and partition method.
    Layout visualization tool:
    https://andreroesti.com/data-layout-viz/data_layout.html

    Parameters:
    -----------
    shape : tuple
        The shape of the tensor (1D or 2D)
    partition : tuple(str, int)
        The partition method for each dimension:
        - 'S': Sharded (distributed across devices)
        - 'R': Replicated (copied to each device)
    device_mesh : tuple, optional
        The mesh of devices (default: (2, 2))

    Returns:
    --------
    tuple
        A tuple containing three lists: (device_dims, size, stride)
        device_dims stands for the device dimension in the size list.
        For example, in the 2x2 GEMM case, the device_dims for 2x2x4x4 will be [0, 1].
    """
    # Handle 1D tensor case
    partition_str = "".join([p[0] for p in partition])
    if len(shape) == 1:
        if partition_str == "S":
            # For 1D tensor with "S", shard across all devices
            total_devices = device_mesh[0]
            shard_size = shape[0] // total_devices
            device_dims = [2]
            size = [1, 1, total_devices, shard_size]
            stride = [0, 0, shard_size, 1]
        elif partition_str == "R":
            # For 1D tensor with "R", replicate across all devices
            total_devices = device_mesh[0]
            device_dims = []
            size = [1, 1, 1, shape[0]]
            stride = [0, 0, 0, 1]
        else:
            raise ValueError(f"Unsupported partition {partition_str} for 1D tensor.")

        return device_dims, size, stride

    # Handle 2D tensor case
    if len(shape) == 2:
        m, n = shape
        if len(device_mesh) == 1:
            a, b = 1, device_mesh[0]
        elif len(device_mesh) == 2:
            if partition[0][0] == "S":
                partition[1] = (partition[1][0], 1 - partition[0][1])
            elif partition[1][0] == "S":  # partition[0][0] == "R"
                partition[0] = (partition[0][0], 1 - partition[1][1])
            else:
                partition[0] = (partition[0], 1)
                partition[1] = (partition[1], 0)
            a, b = device_mesh[-partition[0][1] - 1], device_mesh[-partition[1][1] - 1]
        else:
            a, b = device_mesh[-partition[0][1] - 1], device_mesh[-partition[1][1] - 1]

        if partition_str == "SS":
            # Both dimensions sharded
            device_dims = [0, 1]
            size = [a, b, m // a, n // b]
            stride = [(m // a) * n, n // b, n, 1]

        elif partition_str == "SR":
            # First dim sharded across all devices, second replicated
            total_devices = a * b
            device_dims = [1]
            size = [1, total_devices, m // total_devices, n]
            stride = [0, (m // total_devices) * n, n, 1]

        elif partition_str == "RS":
            # First dim replicated, second sharded across second dim of mesh
            device_dims = [1]
            size = [1, b, m, n // b]
            stride = [(m * n) // (a * b), n // b, n, 1]

        elif partition_str == "RR":
            # Both dimensions replicated
            total_devices = a * b
            device_dims = []
            size = [1, 1, m, n]
            stride = [0, 0, n, 1]
        else:
            raise ValueError(f"Unsupported partition {partition_str} for 2D tensor.")

        return device_dims, size, stride
    raise ValueError(f"Unsupported shape {shape} or partition {partition}.")


def extract_numbers(input_string):
    parts = input_string.split("_")
    numbers = []
    for part in parts:
        if part.isdigit():
            numbers.append(int(part))
    return tuple(numbers)


def map_kernels_to_device_mesh(kernel_shapes, device_shape):
    """
    Maps multiple kernels to a device mesh without overlapping.

    Args:
        kernel_shapes (dict): A dictionary mapping kernel names to their shapes.
                             For 3D kernels: [dim1, dim2, dim3]
                             For 2D kernels: [rows, cols]
                             For 1D kernels: [length]
        device_shape (list): The shape of the device mesh [rows, cols].

    Returns:
        dict: A dictionary mapping kernel names to their occupied device indices.
    """
    # Initialize the device mesh with 0s (unoccupied)
    rows, cols = device_shape
    device_mesh = [[0 for _ in range(cols)] for _ in range(rows)]

    # Dictionary to store the mapping of kernels to device indices
    kernel_to_indices = {}

    # Process each kernel
    for kernel_name, kernel_shape in kernel_shapes.items():
        # If kernel shape is 3D (e.g., [2, 2, 2])
        if len(kernel_shape) == 3:
            # Try both flattening options (e.g., 2x2x2 -> 4x2 or 2x4)
            option1 = [
                kernel_shape[0],
                kernel_shape[1] * kernel_shape[2],
            ]  # dim1 x (dim2*dim3)
            option2 = [
                kernel_shape[0] * kernel_shape[1],
                kernel_shape[2],
            ]  # (dim1*dim2) x dim3

            flattening_options = [option1, option2]

            # Try each flattening option
            placed = False
            for flat_kernel in flattening_options:
                kernel_rows, kernel_cols = flat_kernel

                # Skip if kernel doesn't fit in the mesh with this flattening
                if kernel_rows > rows or kernel_cols > cols:
                    continue

                # Try to place the flattened kernel
                for i in range(rows - kernel_rows + 1):
                    for j in range(cols - kernel_cols + 1):
                        # Check if the region is available
                        available = True
                        for di in range(kernel_rows):
                            for dj in range(kernel_cols):
                                if device_mesh[i + di][j + dj] == 1:
                                    available = False
                                    break
                            if not available:
                                break

                        if available:
                            # Place the kernel
                            indices = []
                            for di in range(kernel_rows):
                                for dj in range(kernel_cols):
                                    device_mesh[i + di][j + dj] = 1  # Mark as occupied
                                    indices.append((i + di, j + dj))
                            kernel_to_indices[kernel_name] = indices
                            placed = True
                            break
                    if placed:
                        break

                if placed:
                    break

        # If kernel shape is 1D (e.g., [4])
        elif len(kernel_shape) == 1:
            kernel_length = kernel_shape[0]

            # Skip if kernel doesn't fit in the mesh
            if kernel_length > rows:
                continue

            # Try to place it as a column
            placed = False
            for j in range(cols):
                if all(device_mesh[i][j] == 0 for i in range(kernel_length)):
                    # Place kernel as a column
                    indices = []
                    for i in range(kernel_length):
                        device_mesh[i][j] = 1  # Mark as occupied
                        indices.append((i, j))
                    kernel_to_indices[kernel_name] = indices
                    placed = True
                    break

        # If kernel shape is 2D (e.g., [2, 2])
        elif len(kernel_shape) == 2:
            kernel_rows, kernel_cols = kernel_shape

            # Skip if kernel doesn't fit in the mesh
            if kernel_rows > rows or kernel_cols > cols:
                continue

            # Try to place the kernel
            placed = False
            for i in range(rows - kernel_rows + 1):
                for j in range(cols - kernel_cols + 1):
                    # Check if the region is available
                    available = True
                    for di in range(kernel_rows):
                        for dj in range(kernel_cols):
                            if device_mesh[i + di][j + dj] == 1:
                                available = False
                                break
                        if not available:
                            break

                    if available:
                        # Place the kernel
                        indices = []
                        for di in range(kernel_rows):
                            for dj in range(kernel_cols):
                                device_mesh[i + di][j + dj] = 1  # Mark as occupied
                                indices.append((i + di, j + dj))
                        kernel_to_indices[kernel_name] = indices
                        placed = True
                        break
                if placed:
                    break

    return kernel_to_indices


def allocate_mem_tiles_with_dtensors(inputs, outputs):
    """
    TODO: make use of the fifth mem tile
    TODO: The current mapping scheme requires the matrices to be completely
    partitioned without remaining elements (shape should be divided by tile num).

    Allocate (shim-tile, mem-tile) pairs for every DTensor that crosses the
    NPU boundary, while respecting the per-mem-tile ObjectFIFO limits.

    The algorithm tries to pack as much traffic as possible into the fewest
    number of memory tiles, only falling back to splitting (called "parts")
    when the requested number of FIFOs would exceed the quota per memory tile.

    Parameters
    ----------
    inputs: Dict[str, List[DTensor]]
        A dictionary mapping function names to lists of DTensor objects as inputs.

    outputs: Dict[str, List[DTensor]]
        A dictionary mapping function names to lists of DTensor objects as outputs.

    Returns
    -------
    Tuple of two elements:
        - tile_map:
            A dictionary mapping tensor names to a list of Part objects.
            Every DTensor may be split into several Part instances when necessary.
            Each Part records which memory tile it resides on and which 8-by-8 tensor tiles it contains.

        - num_pairs:
            The total number of distinct (shim, memory) tile pairs that are allocated.
            This value determines how many off-chip DMA channels will be generated.
    """
    MAX_MEM_TILES = 4  # Maximum number of memory tiles allowed
    MAX_SEND = 6  # Maximum number of producer FIFOs per memory tile (DMA limits)
    MAX_RECV = 6  # Maximum number of consumer FIFOs per memory tile (DMA limits)

    # Running FIFO usage counters for every allocated memory tile
    mem_send_cnt = []
    mem_recv_cnt = []
    Part = namedtuple("Part", "part_id shim_id mem_id tensor_tiles offset size stride")

    # ------------------------------------------------------------------
    # Internal helper: choose an existing or new memory tile that satisfies
    #                  the requested number of SEND and RECV FIFOs.
    # ------------------------------------------------------------------
    def alloc_mem_tile(send_need, recv_need):
        # 1. Attempt to allocate a new memory tile
        if (
            len(mem_send_cnt) < MAX_MEM_TILES
            and send_need <= MAX_SEND
            and recv_need <= MAX_RECV
        ):
            mem_send_cnt.append(send_need)
            mem_recv_cnt.append(recv_need)
            return True, len(mem_send_cnt) - 1  # Index of the newly added tile

        # 2. Otherwise, try to pack into an existing tile
        for i, _ in enumerate(mem_send_cnt):
            if (
                mem_send_cnt[i] + send_need <= MAX_SEND
                and mem_recv_cnt[i] + recv_need <= MAX_RECV
            ):
                mem_send_cnt[i] += send_need
                mem_recv_cnt[i] += recv_need
                return True, i  # Reuse tile at index i

        # 3. If no tile fits, raise an error
        return False, -1

    # ------------------------------------------------------------------
    # Internal helper: split a DTensor into Part instances so each Part fits
    #                  on some memory tile with respect to FIFO limits.
    # ------------------------------------------------------------------
    def make_parts_for_dtensor(dtensor, is_input):
        placement = dtensor.layout.get_placement(dtensor.mapping)
        tensor_tiles = list(placement.keys())
        device_dims, size, stride = calculate_tensor_access(
            dtensor.shape, dtensor.layout.placement, dtensor.mapping
        )
        base_offset = [0, 0, 0, 0]
        if len(device_dims) <= 1:
            factor = 1
        else:
            factor = size[device_dims[0]]

        # Attempt to place the entire tensor in one go
        send_need = len(tensor_tiles) if is_input else 1
        recv_need = 1 if is_input else len(tensor_tiles)
        success, mem_id = alloc_mem_tile(send_need, recv_need)
        if success:
            return [Part(0, mem_id, mem_id, tensor_tiles, base_offset, size, stride)]
        # Must split if single allocation fails
        # Greedy splitting strategy
        parts = []
        part_id = 0
        remaining = tensor_tiles[:]
        start_idx = 0
        while remaining:
            offset = base_offset[:]
            chunk = remaining  # Take as many as capacity allows
            # Shrink the chunk until it fits in FIFO limits
            while chunk:
                send_need = len(chunk) if is_input else 1
                recv_need = 1 if is_input else len(chunk)
                success, mem_id = alloc_mem_tile(send_need, recv_need)
                if success:
                    break
                chunk = chunk[: (len(chunk) - factor)]  # Reduce size and retry
            if not chunk:
                raise RuntimeError(
                    "Failed to allocate (shim, memory) tile: per-tile FIFO limit "
                    "exceeded or no more available tiles."
                )
            if len(device_dims) == 1:
                offset[device_dims[0]] = start_idx
                size[device_dims[0]] = len(chunk)
            else:
                offset[device_dims[1]] = start_idx // factor
                size[device_dims[1]] = len(chunk) // factor
            parts.append(Part(part_id, mem_id, mem_id, chunk, offset, size, stride))
            part_id += 1
            remaining = remaining[len(chunk) :]
            start_idx += len(chunk)
        return parts

    # ------------------------------------------------------------------
    # Build the final mapping from tensor name to a list of Part instances
    # ------------------------------------------------------------------
    tile_map = defaultdict(list)

    # Inputs use SEND quotas since memory tiles act as producers
    for f_name, sub in inputs.items():
        if f_name == "_global":
            continue
        for dtensor in sub["_global"]:
            tile_map[dtensor.name].extend(
                make_parts_for_dtensor(dtensor, is_input=True)
            )

    # Outputs use RECV quotas since memory tiles act as consumers
    for f_name, sub in outputs.items():
        if f_name == "_global":
            continue
        for dtensor in sub["_global"]:
            tile_map[dtensor.name].extend(
                make_parts_for_dtensor(dtensor, is_input=False)
            )

    return tile_map, len(mem_send_cnt)


def codegen_aie_mlir(
    mod,
    func_groups,
    inputs,
    outputs,
    kernel_buf_dicts,
    external_kernels,
    stream_info,
):
    """
    Generates MLIR-AIE code with MLIR module and extra information for multiple kernel functions

    offchip to shim: copy the whole data but reorder
    shim to mem: copy the whole data
    mem to comp: shard the data
    R: same line in object fifo (broadcast)
    S: multiple lines for object fifo, and link with offset

    Parameters
    ----------
    mod: allo._mlir.ir.Module
        The MLIR module built by allo.

    func_groups: Dict[str, List[FuncOp]]
        A dictionary mapping function names to lists of FuncOp objects.

    inputs: Dict[str, List[DTensor]]
        A dictionary mapping function names to lists of DTensor objects as inputs.

    outputs: Dict[str, List[DTensor]]
        A dictionary mapping function names to lists of DTensor objects as outputs.

    kernel_buf_dicts: Dict[str, Dict[str, Tuple[str, List[int]]]]
        The kernel buffer dictionaries for each function in the module.
        The key is the function name, and the value is a dictionary mapping buffer names to their types and shapes.

    external_kernels: Dict[str, List[str]]
        The external kernels that will be injected into the module.
        The key is the name of the function, and the value is a list of names of the external kernels.

    stream_info: Dict[str, List[Tuple[str, str]]]
        The input and output stream of each kernel.
        The key is the name of the kernel, and the value is a list of tuples.
        The first element in the tuple is the name of the stream, the second element is either 'in' or 'out'.
    """
    code = format_str("module {", indent=0)
    tile_map, mem_tile_size = allocate_mem_tiles_with_dtensors(inputs, outputs)
    shim_tile_size = mem_tile_size
    device = "npu1_4col"
    code += format_str(f"aie.device({device}) {{", indent=2)

    # Add external functions
    for func in mod.body.operations:
        if (
            isinstance(func, func_d.FuncOp)
            and "sym_visibility" in func.attributes
            and func.attributes["sym_visibility"].value == "private"
        ):
            code += format_str(str(func), indent=4)

    # Create shim and memory tiles
    # mlir-aie/mlir_tutorials/tutorial-4/flow
    # | Bundle | Channels (In) | Channels (Out) |
    # |-------|---|---|
    # | DMA   | 2 | 2 |
    # | Core  | 2 | 2 |
    # | West  | 4 | 4 |
    # | East  | 4 | 4 |
    # | North | 4 | 6 |
    # | South | 6 | 4 |
    # | FIFO  | 2 | 2 |
    # | Trace | 1 | 0 |
    for shim_id in range(shim_tile_size):
        code += format_str(f"%tile_shim{shim_id} = aie.tile({shim_id}, 0)")
    for mem_id in range(mem_tile_size):
        code += format_str(f"%tile_mem{mem_id} = aie.tile({mem_id}, 1)")

    # Get top function and all other functions
    top_func, all_funcs = get_public_funcs(mod)

    # Track vertical position for tile placement
    aie_mesh = (5, 4)
    y_offset = 2

    # Create compute tiles and store kernel info
    mappings = {}
    for func_name in func_groups:
        if len(inputs[func_name]["_global"]) > 0:
            mappings[func_name] = inputs[func_name]["_global"][0].mapping
        else:
            mappings[func_name] = outputs[func_name]["_global"][0].mapping
    for func_name, tile_ids in map_kernels_to_device_mesh(mappings, aie_mesh).items():
        for idx, func in zip(tile_ids, func_groups[func_name]):
            func_full_name = func.attributes["sym_name"].value
            code += format_str(
                f"%tile_comp_{func_full_name} = aie.tile({idx[0]}, {idx[1] + y_offset})"
            )

    # Create buffers and process function strings for each kernel
    func_strs = []
    for func in all_funcs:
        func_name = func.attributes["sym_name"].value
        tile_name = f"%tile_comp_{func_name}"
        buf_dict = kernel_buf_dicts[func_name]
        buf_name_dict = {}
        for i, name in enumerate(buf_dict.keys()):
            new_name = f"{tile_name}_buf{i}"
            buf_name_dict[name] = new_name
            ele_type, shape = buf_dict[name]
            str_list = list(map(str, shape))
            str_list.append(ele_type)
            buf_type = f"memref<{'x'.join(str_list)}>"
            code += format_str(f"{new_name} = aie.buffer({tile_name}) : {buf_type}")

        # Remove memref.alloc
        pattern_alloc = re.compile(r"^.*memref\.alloc.*\n?", re.MULTILINE)
        func_str = re.sub(pattern_alloc, "", str(func))

        # Replace new buffer name
        pattern_boundary = r"(?<![\w.]){old}(?![\w.])"
        for name, new_name in buf_name_dict.items():
            escaped_name = re.escape(name)
            pattern = pattern_boundary.format(old=escaped_name)
            func_str = re.sub(pattern, new_name, func_str)

        func_strs.append(func_str)

    # Create object FIFOs for each kernel
    tile2fifo = {}
    for io, arg_lst in (("in", inputs), ("out", outputs)):
        for func_name, sub_func_lst in arg_lst.items():
            if func_name == "_global":
                continue
            for idx, dtensor in enumerate(sub_func_lst["_global"]):
                mapping = dtensor.mapping
                spec = dtensor.layout
                placement = spec.get_placement(mapping)
                # shim to mem tile
                for part in tile_map[dtensor.name]:
                    memref_type = get_memref_type_str(dtensor.dtype, part.size)
                    suffix = (
                        f"_{part.part_id}" if len(tile_map[dtensor.name]) > 1 else ""
                    )
                    if io == "in":
                        code += format_str(
                            f"aie.objectfifo @in_shim_{dtensor.name}{suffix}"
                            f"(%tile_shim{part.shim_id}, {{%tile_mem{part.mem_id}}}, 2 : i32)"
                            f" : !aie.objectfifo<{memref_type}>"
                        )
                    else:
                        code += format_str(
                            f"aie.objectfifo @out_shim_{dtensor.name}{suffix}"
                            f"(%tile_mem{part.mem_id}, {{%tile_shim{part.shim_id}}}, 2 : i32)"
                            f" : !aie.objectfifo<{memref_type}>"
                        )
                # mem to comp tile
                for part in tile_map[dtensor.name]:
                    suffix = (
                        f"_{part.part_id}" if len(tile_map[dtensor.name]) > 1 else ""
                    )
                    mem_strs = []
                    mem_stride = [0]
                    for tensor_tile in part.tensor_tiles:
                        arg_name = f"{dtensor.name}_{tensor_tile}"
                        mem_strs.append(f"@{io}_mem_{arg_name}")
                        target_pe_tiles = placement[tensor_tile]
                        tile_strs = []
                        for tile in target_pe_tiles:
                            if dtensor not in sub_func_lst[tile]:
                                continue
                            idx_str = "_".join(map(str, tile))
                            core_name = f"%tile_comp_{func_name}_{idx_str}"
                            tile2fifo.setdefault(core_name, []).append(mem_strs[-1])
                            tile_strs.append(core_name)
                        tile_str = ", ".join(tile_strs)
                        local_mtype = get_memref_type_str(
                            dtensor.dtype, dtensor.get_local_shape()
                        )
                        if io == "in":  # mem -> comp
                            code += format_str(
                                f"aie.objectfifo {mem_strs[-1]}"
                                f"(%tile_mem{part.mem_id}, {{{tile_str}}}, 2 : i32)"
                                f" : !aie.objectfifo<{local_mtype}>"
                            )
                        else:  # comp -> mem
                            code += format_str(
                                f"aie.objectfifo {mem_strs[-1]}"
                                f"({tile_str}, {{%tile_mem{part.mem_id}}}, 2 : i32)"
                                f" : !aie.objectfifo<{local_mtype}>"
                            )
                        mem_stride.append(
                            mem_stride[-1] + np.prod(dtensor.get_local_shape())
                        )

                    # important to sort to guarantee result correctness
                    # output should have spec of SN SN-1 ... S1 S0
                    mem_str = ", ".join(sorted(mem_strs))
                    mem_stride = mem_stride[:-1]
                    if io == "in":
                        code += format_str(
                            f"aie.objectfifo.link "
                            f"[@in_shim_{dtensor.name}{suffix}] -> [{mem_str}]([] {mem_stride})"
                        )
                    else:
                        code += format_str(
                            f"aie.objectfifo.link "
                            f"[{mem_str}] -> [@out_shim_{dtensor.name}{suffix}]({mem_stride} [])"
                        )

    # Create stream object FIFOs from top_func
    stream_ele_types = {}
    stream_in_out = get_stream_in_out(stream_info)
    for op in top_func.entry_block.operations:
        if isinstance(op, allo_d.StreamConstructOp):
            stream_name = op.attributes["name"].value
            if stream_name in stream_in_out:
                in_out = stream_in_out[stream_name]
                stream_type_str = str(op.results.types[0])
                start = stream_type_str.find("<") + 1
                end = stream_type_str.rfind(">")
                type_str, depth_str = stream_type_str[start:end].split(",")
                type_str = type_str.strip()
                if not type_str.startswith("memref"):
                    type_str = f"memref<{type_str}>"
                depth = int(depth_str.strip())
                # Create the stream object FIFO between the two kernels
                code += format_str(
                    f"aie.objectfifo @{stream_name}(%tile_comp_{in_out[0]}, {{%tile_comp_{in_out[1]}}}, {depth} : i32) : !aie.objectfifo<{type_str}>"
                )
                stream_ele_types[stream_name] = type_str

    # Create core computation for each kernel function
    for func_gid, (func, func_str) in enumerate(zip(all_funcs, func_strs)):
        func_name_w_id = func.attributes["sym_name"].value
        func_name = re.match(r"^(.*?)_\d", func_name_w_id).group(1)
        func_id = tuple(map(int, func_name_w_id.split(func_name + "_")[-1].split("_")))
        core_name = f"tile_comp_{func_name_w_id}"
        streams = stream_info[func_name_w_id]

        # Generate core computation
        code += format_str(
            f"%core_0_{func_gid + 2}_{core_name} = aie.core(%{core_name}) {{"
        )
        with format_code(indent=6):
            code += format_str("%global_c0 = arith.constant 0 : index")
            code += format_str("%global_c1 = arith.constant 1 : index")
            code += format_str(
                "%c9223372036854775807 = arith.constant 9223372036854775807 : index"
            )
            code += format_str(
                "scf.for %arg0 = %global_c0 to %c9223372036854775807 step %global_c1 {"
            )
            with format_code(indent=8):
                # Helper function to process FIFOs (acquire or release)
                def process_fifos(is_input, is_acquire):
                    nonlocal code, func_str
                    tensors = (
                        inputs[func_name][func_id]
                        if is_input
                        else outputs[func_name][func_id]
                    )
                    operation = "Consume" if is_input else "Produce"
                    arg_offset = 0 if is_input else len(inputs[func_name][func_id])

                    for arg_id, tensor in enumerate(tensors):
                        # Calculate fifo index and get fifo name
                        if is_input:
                            fifo_name = tile2fifo[f"%{core_name}"][arg_id]
                        else:
                            n_inputs = len(inputs[func_name][func_id])
                            fifo_name = tile2fifo[f"%{core_name}"][n_inputs + arg_id]

                        if is_acquire:
                            # Acquire FIFO and access subview
                            dtype = get_memref_type_str(
                                tensor.dtype, tensor.get_local_shape()
                            )
                            var_prefix = "fifo" if is_input else "fifo_out"
                            local_prefix = "local" if is_input else "local_out"

                            code += format_str(
                                f"%{var_prefix}{arg_id} = aie.objectfifo.acquire {fifo_name}({operation}, 1) : !aie.objectfifosubview<{dtype}>"
                            )
                            code += format_str(
                                f"%{local_prefix}{arg_id} = aie.objectfifo.subview.access %{var_prefix}{arg_id}[0] : !aie.objectfifosubview<{dtype}> -> {dtype}"
                            )

                            # Replace argument in function string
                            arg_name = f"%arg{arg_id + arg_offset}"
                            local_name = f"%{local_prefix}{arg_id}"
                            func_str = func_str.replace(arg_name, local_name)
                        else:
                            # Release FIFO
                            code += format_str(
                                f"aie.objectfifo.release {fifo_name}({operation}, 1)"
                            )

                # Acquire input and output FIFOs
                process_fifos(is_input=True, is_acquire=True)
                process_fifos(is_input=False, is_acquire=True)

                # Fix call operations
                while " call @" in func_str:
                    func_str = func_str.replace(" call @", " func.call @")

                # Process stream operations
                stream_code, func_str = process_stream_operations(
                    func_str,
                    streams,
                    len(inputs[func_name]["_global"])
                    + len(outputs[func_name]["_global"]),
                    stream_ele_types,
                )
                code += stream_code

                # Release input and output FIFOs
                process_fifos(is_input=True, is_acquire=False)
                process_fifos(is_input=False, is_acquire=False)

            code += format_str("}")
            code += format_str("aie.end")

        # Add linking information if needed
        code += "    }"
        if len(external_kernels.get(func_name_w_id, [])) > 0:
            code += ' {link_with = "external.o"}\n'
        else:
            code += "\n"

    # Create runtime sequence with all inputs and outputs
    in_args = []
    out_args = []
    global_idx = 0
    for io_lst, io_args, io in ((inputs, in_args, "in"), (outputs, out_args, "out")):
        for i, dtensor in enumerate(
            io_lst["_global"], start=global_idx if io == "out" else 0
        ):
            global_memref_type = get_memref_type_str(dtensor.dtype, dtensor.shape)
            io_args.append(f"%arg{i}: {global_memref_type}")
            if io == "in":
                global_idx += 1

    # Create dma transfer from off-chip mem to shim tile
    code += format_str(
        f"aiex.runtime_sequence({', '.join(in_args)}, {', '.join(out_args)}) {{"
    )

    with format_code(indent=6):

        def process_dma_operations(tensor_lst, is_input):
            nonlocal code
            prefix = "in" if is_input else "out"
            start_idx = 0 if is_input else global_idx
            for idx, dtensor in enumerate(tensor_lst, start=start_idx):
                for part in tile_map[dtensor.name]:
                    suffix = (
                        f"_{part.part_id}" if len(tile_map[dtensor.name]) > 1 else ""
                    )
                    memref_type = get_memref_type_str(dtensor.dtype, dtensor.shape)
                    dma_attr = (
                        f"id = {idx} : i64, "
                        f"{'issue_token = true, ' if is_input else ''}"
                        f"metadata = @{prefix}_shim_{dtensor.name}{suffix}"
                    )
                    code += format_str(
                        f"aiex.npu.dma_memcpy_nd(0, 0, %arg{idx}{part.offset}{part.size}{part.stride})"
                        f" {{{dma_attr}}} : {memref_type}"
                    )

        process_dma_operations(inputs["_global"], True)
        process_dma_operations(outputs["_global"], False)

        def process_dma_wait(tensor_lst, is_input):
            nonlocal code
            prefix = "in" if is_input else "out"
            for dtensor in tensor_lst:
                for part in tile_map[dtensor.name]:
                    suffix = (
                        f"_{part.part_id}" if len(tile_map[dtensor.name]) > 1 else ""
                    )
                    code += format_str(
                        f"aiex.npu.dma_wait {{symbol = @{prefix}_shim_{dtensor.name}{suffix}}}"
                    )

        process_dma_wait(inputs["_global"], True)
        process_dma_wait(outputs["_global"], False)

    code += format_str("}")
    code += format_str("}", indent=2)
    code += "}"
    return code


def lower_tensor_to_memref(mod):
    passes = [
        # "linalg-generalize-named-ops",
        # "linalg-fuse-elementwise-ops",
        "func.func(convert-linalg-to-affine-loops),lower-affine",
    ]
    pipeline = f'builtin.module({",".join(passes)})'
    with mod.context:
        mlir_pass_manager.parse(pipeline).run(mod.operation)


def record_local_buffer(mod):
    kernel_buf_dicts = {}
    _, funcs = get_public_funcs(mod)

    def traverse_operations(operations, buf_dict):
        for op in operations:
            if op.operation.name == "memref.alloc":
                name = op.result.get_name()
                dtype, shape = get_dtype_and_shape_from_type(op.result.type)
                buf_dict[name] = (dtype, shape)

            # Recursively traverse into all regions and blocks of the operation
            for region in op.regions:
                for block in region.blocks:
                    traverse_operations(block.operations, buf_dict)

    for func in funcs:
        func_name = func.attributes["sym_name"].value
        buf_dict = {}

        # Start traversal from the top-level operations of the function
        for block in func.regions[0].blocks:
            traverse_operations(block.operations, buf_dict)

        kernel_buf_dicts[func_name] = buf_dict

    return kernel_buf_dicts


def get_func_groups(module):
    _, all_funcs = get_public_funcs(module)
    func_groups = {}
    for func in all_funcs:
        func_name_w_id = func.attributes["sym_name"].value
        func_name = re.match(r"^(.*?)_\d", func_name_w_id).group(1)
        if func_name not in func_groups:
            func_groups[func_name] = []
        func_groups[func_name].append(func)
    return func_groups


class AIEModule:
    def __init__(
        self,
        module,
        top_func_name,
        func_args,
        project,
        stream_info,
    ):
        self.module = module
        self.top_func_name = top_func_name
        self.project = project
        self.module = module
        self.func_args = func_args
        self.stream_info = stream_info

    def build(self):
        assert "MLIR_AIE_INSTALL_DIR" in os.environ, "Please set MLIR_AIE_INSTALL_DIR"
        assert "PEANO_INSTALL_DIR" in os.environ, "Please set PEANO_INSTALL_DIR"
        os.makedirs(os.path.join(self.project, "build"), exist_ok=True)
        with open(
            os.path.join(self.project, "original.mlir"), "w", encoding="utf-8"
        ) as f:
            f.write(str(self.module))
        # Create a dictionary to store the kernel functions
        func_groups = get_func_groups(self.module)
        inputs = {}
        outputs = {}
        for func_name, funcs in func_groups.items():
            inputs[func_name] = {}
            outputs[func_name] = {}
            inputs[func_name]["_global"] = []
            outputs[func_name]["_global"] = []
            for func in funcs:
                # Even for functions inside the same group, the in/out arguments may be different
                func_name_w_id = func.attributes["sym_name"].value
                func_id = tuple(
                    map(int, func_name_w_id.split(func_name + "_")[-1].split("_"))
                )
                in_idx, out_idx = analyze_read_write_patterns(func)
                for io_lst, io_idx in ((inputs, in_idx), (outputs, out_idx)):
                    io_lst[func_name][func_id] = []
                    for idx in io_idx:
                        dtensor = self.func_args[func_name_w_id][idx]
                        if dtensor not in io_lst[func_name]["_global"]:
                            io_lst[func_name]["_global"].append(dtensor)
                        io_lst[func_name][func_id].append(dtensor)
        for io_lst in (inputs, outputs):
            io_lst["_global"] = []
            for func_name, sub_func_lst in io_lst.items():
                if func_name == "_global":
                    continue
                for tensor in sub_func_lst["_global"]:
                    if tensor not in io_lst["_global"]:
                        io_lst["_global"].append(tensor)
        self.inputs = inputs
        self.outputs = outputs
        external_kernels = inject_aie_kernels(self.module)
        lower_tensor_to_memref(self.module)
        kernel_buf_dicts = record_local_buffer(self.module)
        # update the function groups
        func_groups = get_func_groups(self.module)
        code = codegen_aie_mlir(
            self.module,
            func_groups,
            inputs,
            outputs,
            kernel_buf_dicts,
            external_kernels,
            self.stream_info,
        )
        with open(os.path.join(self.project, "top.mlir"), "w", encoding="utf-8") as f:
            f.write(code)
        # compile external kernels
        kernel_code, generated_kernels = codegen_external_kernels(external_kernels)
        if len(generated_kernels) > 0:
            with open(
                os.path.join(self.project, "external.cc"), "w", encoding="utf-8"
            ) as f:
                f.write(kernel_code)
            path = os.path.join(os.path.dirname(__file__), "aie_kernels")
            cmd = f"cd {self.project} && $PEANO_INSTALL_DIR/bin/clang++ -O2 -v -std=c++20 --target=aie2-none-unknown-elf -Wno-parentheses -Wno-attributes -Wno-macro-redefined -DNDEBUG -I $(dirname $(which aie-opt))/../include -I $MLIR_AIE_INSTALL_DIR/../aie_kernels/aie2 -c external.cc -o external.o"
            process = subprocess.Popen(cmd, shell=True)
            process.wait()
            if process.returncode != 0:
                raise RuntimeError("Failed to compile external kernels.")
        # build mlir-aie
        cmd = f"cd {self.project} && PYTHONPATH=$MLIR_AIE_INSTALL_DIR/python aiecc.py --aie-generate-cdo --aie-generate-npu --no-compile-host --no-xchesscc --no-xbridge --xclbin-name=build/final.xclbin --npu-insts-name=insts.txt top.mlir"
        process = subprocess.Popen(cmd, shell=True)
        process.wait()
        if process.returncode != 0:
            raise RuntimeError("Failed to compile the MLIR-AIE code")
        path = os.path.dirname(__file__)
        path = os.path.join(path, "../harness/aie")
        os.system(f"cp -r {path}/* {self.project}")
        host_code = codegen_host(inputs["_global"], outputs["_global"])
        with open(os.path.join(self.project, "test.cpp"), "w", encoding="utf-8") as f:
            f.write(host_code)
        cmd = f"cd {self.project}/build && cmake .. -DTARGET_NAME=top -DMLIR_AIE_DIR=$MLIR_AIE_INSTALL_DIR/.. && cmake --build . --config Release"
        process = subprocess.Popen(cmd, shell=True)
        process.wait()
        if process.returncode != 0:
            raise RuntimeError("Failed to build AIE project.")
        return self

    def __call__(self, *args):
        # suppose the last argument is output
        for i, arg in enumerate(args[:-1]):
            with open(
                os.path.join(self.project, f"input{i}.data"), "w", encoding="utf-8"
            ) as f:
                f.write("\n".join([str(i) for i in arg.flatten()]))
        cmd = f"cd {self.project} && ./build/top -x build/final.xclbin -i insts.txt -k MLIR_AIE"
        process = subprocess.Popen(cmd, shell=True)
        process.wait()
        if process.returncode != 0:
            raise RuntimeError("Failed to execute AIE code.")
        # TODO: need to complete multiple outputs rules
        result = read_tensor_from_file(
            self.outputs["_global"][-1].dtype,
            args[-1].shape,
            f"{self.project}/output.data",
        )
        args[-1][:] = result
